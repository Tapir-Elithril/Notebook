
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Tapir's Notebook">
      
      
        <meta name="author" content="杨亿酬">
      
      
        <link rel="canonical" href="https://tapir-elithril.github.io/Notebook/fa25/ml/note/">
      
      
        <link rel="prev" href="../">
      
      
        <link rel="next" href="../../icv/">
      
      
        
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>笔记 - Tapir's Notebook</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif+SC:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Noto Serif SC";--md-code-font:"JetBrains Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#machine-learning" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="Tapir&#39;s Notebook" class="md-header__button md-logo" aria-label="Tapir's Notebook" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Tapir's Notebook
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              笔记
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="orange"  aria-label="切换至夜间模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换至夜间模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="orange"  aria-label="切换至日间模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换至日间模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/Tapir-Elithril/Notebook" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    Tapir-Elithril/Notebook
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
  
    
  
  首页

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../tools/" class="md-tabs__link">
          
  
  
    
  
  tools

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../fa23/" class="md-tabs__link">
          
  
  
    
  
  fa23

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../sp24/" class="md-tabs__link">
          
  
  
    
  
  sp24

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../fa24/" class="md-tabs__link">
          
  
  
    
  
  fa24

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../sp25/" class="md-tabs__link">
          
  
  
    
  
  sp25

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
  
    
  
  fa25

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../research/data/note/" class="md-tabs__link">
          
  
  
    
  
  research

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Tapir&#39;s Notebook" class="md-nav__button md-logo" aria-label="Tapir's Notebook" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Tapir's Notebook
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/Tapir-Elithril/Notebook" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    Tapir-Elithril/Notebook
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    首页
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../tools/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    tools
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    tools
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools/git/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Git
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools/linux/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Linux
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools/markdown/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Markdown
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_5" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../tools/latex/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    LaTeX
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_5" id="__nav_2_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    LaTeX
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools/latex/format/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    文献
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools/latex/symbols/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    常用符号
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools/makefile/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Makefile
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../fa23/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    fa23
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    fa23
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa23/military_training/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    军训
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa23/math_analysis1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    数学分析(甲)I(H)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa23/programming/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    程序设计与算法基础
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa23/linear_algebra1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    线性代数I(H)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa23/modern_history/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    中国近现代史纲要(H)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa23/morality_law/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    思想道德与法治
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa23/political_philosophy/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    近代西方政治哲学导论
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa23/astronomy/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    天文学导论
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa23/psychology/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    心理学及应用
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa23/career_planning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    职业生涯规划
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa23/reform_and_openup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    中国改革开放史
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa23/orienteering/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    定向越野
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa23/fitness/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    身体素质课
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../sp24/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    sp24
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    sp24
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp24/math_analysis2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    数学分析(甲)II(H)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../sp24/sys1/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    计算机系统I
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    计算机系统I
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp24/sys1/CPU/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    单周期CPU
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp24/physics1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    普通物理学I(H)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp24/discrete_math/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    离散数学理论基础
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp24/linear_algebra2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    线性代数II(H)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_7" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../sp24/fds/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    数据结构基础
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_7" id="__nav_4_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    数据结构基础
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp24/fds/struct/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    常见结构体
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp24/physics1_lab/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    普通物理学实验I
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp24/cyber_security/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    网络空间安全导论
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp24/piano/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    打开艺术之门——钢琴
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp24/swimming/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    游泳(初级)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp24/fitness/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    身体素质课
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp24/situation_policy1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    形势与政策I
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp24/ctf/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    课程综合实践I——安全攻防实践基础(CTF)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../fa24/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    fa24
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5" id="__nav_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    fa24
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../fa24/sys2/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    计算机系统II
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    计算机系统II
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa24/sys2/note/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    课程笔记
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa24/physics2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    普通物理学II(H)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_4" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../fa24/ads/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    高级数据结构与算法分析
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    高级数据结构与算法分析
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa24/ads/note/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    课程笔记
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa24/probability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    概率论(H)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa24/aid/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    人工智能引论
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa24/military_theory/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    军事理论
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa24/physics2_lab/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    普通物理学实验II
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa24/tea/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    茶文化与茶健康
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../fa24/aerobics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    健美操
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../sp25/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    sp25
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6" id="__nav_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    sp25
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../sp25/sys3/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    计算机系统III
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    计算机系统III
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp25/sys3/note/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    笔记
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../sp25/db/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    数据库系统
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6_3" id="__nav_6_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    数据库系统
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp25/db/note/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    笔记
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6_4" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../sp25/oop/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    面向对象程序设计
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6_4" id="__nav_6_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    面向对象程序设计
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp25/oop/note/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    笔记
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp25/marx/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    马克思主义基本原理(H)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp25/xi/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    习近平新时代中国特色社会主义思想概论
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp25/line_dance/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    排舞
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6_8" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../sp25/data_market/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    数据要素交易基础
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6_8" id="__nav_6_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_8">
            <span class="md-nav__icon md-icon"></span>
            
  
    数据要素交易基础
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sp25/data_market/note/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    笔记
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    fa25
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7" id="__nav_7_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    fa25
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    机器学习
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_2" id="__nav_7_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_7_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    机器学习
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    笔记
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    笔记
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lecture-1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 1
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 1">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Supervised learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unsupervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Unsupervised learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reinforcement" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reinforcement
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 2
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 2">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#supervised-learning-procedure" class="md-nav__link">
    <span class="md-ellipsis">
      
        Supervised Learning Procedure
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-methods-for-regression" class="md-nav__link">
    <span class="md-ellipsis">
      
        Linear Methods for Regression
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 3
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 3">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#statistical-model-of-regression-mle" class="md-nav__link">
    <span class="md-ellipsis">
      
        Statistical model of regression —— MLE
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#regularizationridge-regression" class="md-nav__link">
    <span class="md-ellipsis">
      
        Regularization/Ridge Regression 岭回归
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lassosparse-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        LASSO:sparse model
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 4
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 4">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bias-variance-decomposition" class="md-nav__link">
    <span class="md-ellipsis">
      
        Bias &amp; Variance Decomposition
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Bias &amp; Variance Decomposition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-bias-variance-trade-off" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Bias-Variance Trade-off
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross-validation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Cross-Validation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classification" class="md-nav__link">
    <span class="md-ellipsis">
      
        Classification
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#binary-classifier-to-multi-class-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      
        Binary Classifier to Multi-class Classifier
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#regression-to-classification" class="md-nav__link">
    <span class="md-ellipsis">
      
        Regression to Classification
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-5" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 5
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 5">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gradient-descent" class="md-nav__link">
    <span class="md-ellipsis">
      
        Gradient Descent
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#support-vector-machine" class="md-nav__link">
    <span class="md-ellipsis">
      
        Support Vector Machine
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Support Vector Machine">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#geometrical-margin" class="md-nav__link">
    <span class="md-ellipsis">
      
        Geometrical margin
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#maximum-margin-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      
        Maximum Margin Classifier
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#support-vector" class="md-nav__link">
    <span class="md-ellipsis">
      
        Support Vector
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-6" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 6
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 6">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lagrange-multipliers-and-the-karush-kuhn-tucker-conditions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lagrange Multipliers and the Karush-Kuhn-Tucker conditions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lagrange Multipliers and the Karush-Kuhn-Tucker conditions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#unconstrained-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Unconstrained Optimization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#constrained-optimizationequality-constraints" class="md-nav__link">
    <span class="md-ellipsis">
      
        Constrained Optimization:Equality Constraints
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lagrange-multiplier" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lagrange Multiplier
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#constrained-optimizationinequality-constraints" class="md-nav__link">
    <span class="md-ellipsis">
      
        Constrained Optimization:Inequality Constraints
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kkt-conditions" class="md-nav__link">
    <span class="md-ellipsis">
      
        *KKT conditions
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#python-basic" class="md-nav__link">
    <span class="md-ellipsis">
      
        Python Basic
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-7" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 7
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 7">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#generalized-linear-function" class="md-nav__link">
    <span class="md-ellipsis">
      
        Generalized Linear Function
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kernel-method" class="md-nav__link">
    <span class="md-ellipsis">
      
        Kernel Method
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Kernel Method">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#maximum-margin-classifier_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Maximum Margin Classifier
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#common-kernel-functions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Common Kernel Functions
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-tree" class="md-nav__link">
    <span class="md-ellipsis">
      
        Decision Tree
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-8" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 8
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 8">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#picking-the-best-feature" class="md-nav__link">
    <span class="md-ellipsis">
      
        Picking the best feature
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cartclassification-and-regression-trees" class="md-nav__link">
    <span class="md-ellipsis">
      
        CART(Classification and Regression Trees)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-9" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 9
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 9">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#when-to-stop" class="md-nav__link">
    <span class="md-ellipsis">
      
        when to stop?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-to-prune" class="md-nav__link">
    <span class="md-ellipsis">
      
        how to prune?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cart-for-classification" class="md-nav__link">
    <span class="md-ellipsis">
      
        CART for classification
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#artificial-neural-network-deep-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Artificial Neural Network &amp; Deep Learning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Artificial Neural Network &amp; Deep Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#perceptron" class="md-nav__link">
    <span class="md-ellipsis">
      
        perceptron
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-10" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 10
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 10">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backpropagation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Backpropagation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-net-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Neural Net models
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#activation-function" class="md-nav__link">
    <span class="md-ellipsis">
      
        Activation Function
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-11" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 11
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-12" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 12
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 12">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#quiz" class="md-nav__link">
    <span class="md-ellipsis">
      
        quiz
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-13" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 13
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 13">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#net-topology-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      
        Net topology &amp; CNN
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-14" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 14
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-15" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 15
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 15">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#natural-language-processing" class="md-nav__link">
    <span class="md-ellipsis">
      
        Natural Language Processing
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Natural Language Processing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#recurrent-neural-networksrnn" class="md-nav__link">
    <span class="md-ellipsis">
      
        Recurrent Neural Networks(RNN)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-16" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 16
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 16">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lstm" class="md-nav__link">
    <span class="md-ellipsis">
      
        LSTM
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rnn-types" class="md-nav__link">
    <span class="md-ellipsis">
      
        RNN types
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention-mechanism" class="md-nav__link">
    <span class="md-ellipsis">
      
        Attention Mechanism
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer" class="md-nav__link">
    <span class="md-ellipsis">
      
        Transformer
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-17" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 17
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 17">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bert" class="md-nav__link">
    <span class="md-ellipsis">
      
        BERT
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batch-normalization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Batch Normalization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-augmentation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Data Augmentation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-network-pruning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Neural Network Pruning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Neural Network Pruning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#weight-level" class="md-nav__link">
    <span class="md-ellipsis">
      
        weight-level
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#filter-level" class="md-nav__link">
    <span class="md-ellipsis">
      
        filter-level
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#layer-levelblock-level" class="md-nav__link">
    <span class="md-ellipsis">
      
        layer-level/block-level
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generative-adversarial-networksgan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Generative Adversarial Networks(GAN)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diffusion" class="md-nav__link">
    <span class="md-ellipsis">
      
        *Diffusion
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-18" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 18
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 18">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#adversial-attacks-and-defense" class="md-nav__link">
    <span class="md-ellipsis">
      
        Adversial Attacks and Defense
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Adversial Attacks and Defense">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#attack" class="md-nav__link">
    <span class="md-ellipsis">
      
        attack
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#defense" class="md-nav__link">
    <span class="md-ellipsis">
      
        defense
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-network-architecture-searchnas" class="md-nav__link">
    <span class="md-ellipsis">
      
        Neural Network Architecture Search(NAS)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#combining-modelsensemble-methods" class="md-nav__link">
    <span class="md-ellipsis">
      
        Combining Models(Ensemble Methods)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Combining Models(Ensemble Methods)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#baggingbootstrap-aggregating" class="md-nav__link">
    <span class="md-ellipsis">
      
        Bagging(Bootstrap Aggregating)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random-forest" class="md-nav__link">
    <span class="md-ellipsis">
      
        Random Forest
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#boosting" class="md-nav__link">
    <span class="md-ellipsis">
      
        Boosting
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-boosting-decision-treegbdt" class="md-nav__link">
    <span class="md-ellipsis">
      
        Gradient Boosting Decision Tree(GBDT)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-19" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 19
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 19">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#k-nearest-neighbor-classifierknn" class="md-nav__link">
    <span class="md-ellipsis">
      
        K-Nearest Neighbor Classifier(KNN)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metric-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Metric Learning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Metric Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mmcmahalanobis-metric-for-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        MMC(Mahalanobis Metric for Clustering)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#aknn-search" class="md-nav__link">
    <span class="md-ellipsis">
      
        AKNN Search
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="AKNN Search">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kd-tree" class="md-nav__link">
    <span class="md-ellipsis">
      
        KD-tree
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-20" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 20
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 20">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#quiz_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        quiz
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-21" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 21
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 21">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#reinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reinforcement Learning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Reinforcement Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#markov-decision-processmdp" class="md-nav__link">
    <span class="md-ellipsis">
      
        Markov Decision Process(MDP)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-22" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 22
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 22">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dynamic-programming" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dynamic Programming
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#monte-carlo-method" class="md-nav__link">
    <span class="md-ellipsis">
      
        Monte Carlo Method
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-23" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 23
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 23">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#temporal-difference-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Temporal-Difference Learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sarsa" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sarsa
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#q-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Q-Learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deep-q-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Deep Q-Learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#double-q-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Double Q-Learning
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-24" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 24
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 24">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#policy-gradient-methods" class="md-nav__link">
    <span class="md-ellipsis">
      
        Policy Gradient Methods
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dimensionality-reduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dimensionality Reduction
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dimensionality Reduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pca" class="md-nav__link">
    <span class="md-ellipsis">
      
        PCA
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-25" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 25
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 25">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#linear-discriminant-analysislda" class="md-nav__link">
    <span class="md-ellipsis">
      
        Linear Discriminant Analysis(LDA)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#manifold-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Manifold Learning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Manifold Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#isomap" class="md-nav__link">
    <span class="md-ellipsis">
      
        ISOMAP
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#locally-linear-embeddinglle" class="md-nav__link">
    <span class="md-ellipsis">
      
        Locally Linear Embedding(LLE)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#robust-pca" class="md-nav__link">
    <span class="md-ellipsis">
      
        Robust PCA
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autoencoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        AutoEncoder
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-26" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 26
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 26">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        Clustering
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Clustering">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        原型聚类
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        密度聚类
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        层次聚类
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature-selection" class="md-nav__link">
    <span class="md-ellipsis">
      
        feature selection
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="feature selection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        过滤式选择
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        包裹式选择
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        嵌入式选择
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse-encoding" class="md-nav__link">
    <span class="md-ellipsis">
      
        sparse encoding
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="sparse encoding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#compressive-sensing" class="md-nav__link">
    <span class="md-ellipsis">
      
        compressive sensing
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-27" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 27
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 27">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#semi-supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Semi-supervised learning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Semi-supervised learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        生成式方法
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#svm" class="md-nav__link">
    <span class="md-ellipsis">
      
        半监督SVM
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      
        图半监督学习
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#disagreement" class="md-nav__link">
    <span class="md-ellipsis">
      
        基于分歧disagreement的方法
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      
        半监督聚类
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-28" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 28
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 28">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      
        概率图模型
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="概率图模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hmm" class="md-nav__link">
    <span class="md-ellipsis">
      
        隐马尔可夫模型(HMM)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mrf" class="md-nav__link">
    <span class="md-ellipsis">
      
        马尔可夫随机场(MRF)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#crf" class="md-nav__link">
    <span class="md-ellipsis">
      
        条件随机场(CRF)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    <span class="md-ellipsis">
      
        学习与推断
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    <span class="md-ellipsis">
      
        近似推断
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#final-review" class="md-nav__link">
    <span class="md-ellipsis">
      
        Final Review
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../icv/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    计算机视觉导论
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_3" id="__nav_7_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    计算机视觉导论
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../icv/note/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    笔记
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tcs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    理论计算机科学导引
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../opt/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    优化基本理论与方法
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_6" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../quantum/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    量子计算理论基础与软件系统
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6" id="__nav_7_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    量子计算理论基础与软件系统
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quantum/note/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    笔记
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mao/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    毛泽东思想与中国特色社会主义理论体系概论（H）
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tennis/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    网球（初级）
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    research
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            
  
    research
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_8_1" >
        
          
          <label class="md-nav__link" for="__nav_8_1" id="__nav_8_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    data_target
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    data_target
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../research/data/note/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Data Target
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../research/data/paper/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    paper_list
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../research/data/review/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    review
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_8_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../research/kaggle/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    kaggle
  

    
  </span>
  
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    kaggle
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_8_3" >
        
          
          <label class="md-nav__link" for="__nav_8_3" id="__nav_8_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    llm_infra
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    llm_infra
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../research/llm_vuln/kvcache/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    kvcache
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../research/llm_vuln/llm_vulnerability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    llm_vulnerability
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../research/llm_vuln/mcp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    mcp
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lecture-1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 1
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 1">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Supervised learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unsupervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Unsupervised learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reinforcement" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reinforcement
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 2
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 2">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#supervised-learning-procedure" class="md-nav__link">
    <span class="md-ellipsis">
      
        Supervised Learning Procedure
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-methods-for-regression" class="md-nav__link">
    <span class="md-ellipsis">
      
        Linear Methods for Regression
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 3
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 3">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#statistical-model-of-regression-mle" class="md-nav__link">
    <span class="md-ellipsis">
      
        Statistical model of regression —— MLE
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#regularizationridge-regression" class="md-nav__link">
    <span class="md-ellipsis">
      
        Regularization/Ridge Regression 岭回归
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lassosparse-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        LASSO:sparse model
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 4
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 4">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bias-variance-decomposition" class="md-nav__link">
    <span class="md-ellipsis">
      
        Bias &amp; Variance Decomposition
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Bias &amp; Variance Decomposition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-bias-variance-trade-off" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Bias-Variance Trade-off
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross-validation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Cross-Validation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classification" class="md-nav__link">
    <span class="md-ellipsis">
      
        Classification
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#binary-classifier-to-multi-class-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      
        Binary Classifier to Multi-class Classifier
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#regression-to-classification" class="md-nav__link">
    <span class="md-ellipsis">
      
        Regression to Classification
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-5" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 5
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 5">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gradient-descent" class="md-nav__link">
    <span class="md-ellipsis">
      
        Gradient Descent
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#support-vector-machine" class="md-nav__link">
    <span class="md-ellipsis">
      
        Support Vector Machine
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Support Vector Machine">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#geometrical-margin" class="md-nav__link">
    <span class="md-ellipsis">
      
        Geometrical margin
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#maximum-margin-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      
        Maximum Margin Classifier
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#support-vector" class="md-nav__link">
    <span class="md-ellipsis">
      
        Support Vector
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-6" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 6
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 6">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lagrange-multipliers-and-the-karush-kuhn-tucker-conditions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lagrange Multipliers and the Karush-Kuhn-Tucker conditions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lagrange Multipliers and the Karush-Kuhn-Tucker conditions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#unconstrained-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Unconstrained Optimization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#constrained-optimizationequality-constraints" class="md-nav__link">
    <span class="md-ellipsis">
      
        Constrained Optimization:Equality Constraints
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lagrange-multiplier" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lagrange Multiplier
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#constrained-optimizationinequality-constraints" class="md-nav__link">
    <span class="md-ellipsis">
      
        Constrained Optimization:Inequality Constraints
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kkt-conditions" class="md-nav__link">
    <span class="md-ellipsis">
      
        *KKT conditions
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#python-basic" class="md-nav__link">
    <span class="md-ellipsis">
      
        Python Basic
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-7" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 7
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 7">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#generalized-linear-function" class="md-nav__link">
    <span class="md-ellipsis">
      
        Generalized Linear Function
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kernel-method" class="md-nav__link">
    <span class="md-ellipsis">
      
        Kernel Method
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Kernel Method">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#maximum-margin-classifier_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Maximum Margin Classifier
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#common-kernel-functions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Common Kernel Functions
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-tree" class="md-nav__link">
    <span class="md-ellipsis">
      
        Decision Tree
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-8" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 8
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 8">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#picking-the-best-feature" class="md-nav__link">
    <span class="md-ellipsis">
      
        Picking the best feature
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cartclassification-and-regression-trees" class="md-nav__link">
    <span class="md-ellipsis">
      
        CART(Classification and Regression Trees)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-9" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 9
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 9">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#when-to-stop" class="md-nav__link">
    <span class="md-ellipsis">
      
        when to stop?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-to-prune" class="md-nav__link">
    <span class="md-ellipsis">
      
        how to prune?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cart-for-classification" class="md-nav__link">
    <span class="md-ellipsis">
      
        CART for classification
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#artificial-neural-network-deep-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Artificial Neural Network &amp; Deep Learning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Artificial Neural Network &amp; Deep Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#perceptron" class="md-nav__link">
    <span class="md-ellipsis">
      
        perceptron
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-10" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 10
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 10">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backpropagation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Backpropagation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-net-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Neural Net models
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#activation-function" class="md-nav__link">
    <span class="md-ellipsis">
      
        Activation Function
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-11" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 11
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-12" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 12
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 12">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#quiz" class="md-nav__link">
    <span class="md-ellipsis">
      
        quiz
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-13" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 13
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 13">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#net-topology-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      
        Net topology &amp; CNN
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-14" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 14
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-15" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 15
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 15">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#natural-language-processing" class="md-nav__link">
    <span class="md-ellipsis">
      
        Natural Language Processing
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Natural Language Processing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#recurrent-neural-networksrnn" class="md-nav__link">
    <span class="md-ellipsis">
      
        Recurrent Neural Networks(RNN)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-16" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 16
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 16">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lstm" class="md-nav__link">
    <span class="md-ellipsis">
      
        LSTM
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rnn-types" class="md-nav__link">
    <span class="md-ellipsis">
      
        RNN types
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention-mechanism" class="md-nav__link">
    <span class="md-ellipsis">
      
        Attention Mechanism
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer" class="md-nav__link">
    <span class="md-ellipsis">
      
        Transformer
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-17" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 17
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 17">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bert" class="md-nav__link">
    <span class="md-ellipsis">
      
        BERT
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batch-normalization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Batch Normalization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-augmentation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Data Augmentation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-network-pruning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Neural Network Pruning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Neural Network Pruning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#weight-level" class="md-nav__link">
    <span class="md-ellipsis">
      
        weight-level
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#filter-level" class="md-nav__link">
    <span class="md-ellipsis">
      
        filter-level
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#layer-levelblock-level" class="md-nav__link">
    <span class="md-ellipsis">
      
        layer-level/block-level
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generative-adversarial-networksgan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Generative Adversarial Networks(GAN)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diffusion" class="md-nav__link">
    <span class="md-ellipsis">
      
        *Diffusion
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-18" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 18
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 18">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#adversial-attacks-and-defense" class="md-nav__link">
    <span class="md-ellipsis">
      
        Adversial Attacks and Defense
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Adversial Attacks and Defense">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#attack" class="md-nav__link">
    <span class="md-ellipsis">
      
        attack
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#defense" class="md-nav__link">
    <span class="md-ellipsis">
      
        defense
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-network-architecture-searchnas" class="md-nav__link">
    <span class="md-ellipsis">
      
        Neural Network Architecture Search(NAS)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#combining-modelsensemble-methods" class="md-nav__link">
    <span class="md-ellipsis">
      
        Combining Models(Ensemble Methods)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Combining Models(Ensemble Methods)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#baggingbootstrap-aggregating" class="md-nav__link">
    <span class="md-ellipsis">
      
        Bagging(Bootstrap Aggregating)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random-forest" class="md-nav__link">
    <span class="md-ellipsis">
      
        Random Forest
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#boosting" class="md-nav__link">
    <span class="md-ellipsis">
      
        Boosting
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-boosting-decision-treegbdt" class="md-nav__link">
    <span class="md-ellipsis">
      
        Gradient Boosting Decision Tree(GBDT)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-19" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 19
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 19">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#k-nearest-neighbor-classifierknn" class="md-nav__link">
    <span class="md-ellipsis">
      
        K-Nearest Neighbor Classifier(KNN)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metric-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Metric Learning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Metric Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mmcmahalanobis-metric-for-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        MMC(Mahalanobis Metric for Clustering)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#aknn-search" class="md-nav__link">
    <span class="md-ellipsis">
      
        AKNN Search
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="AKNN Search">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kd-tree" class="md-nav__link">
    <span class="md-ellipsis">
      
        KD-tree
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-20" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 20
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 20">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#quiz_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        quiz
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-21" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 21
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 21">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#reinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reinforcement Learning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Reinforcement Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#markov-decision-processmdp" class="md-nav__link">
    <span class="md-ellipsis">
      
        Markov Decision Process(MDP)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-22" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 22
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 22">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dynamic-programming" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dynamic Programming
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#monte-carlo-method" class="md-nav__link">
    <span class="md-ellipsis">
      
        Monte Carlo Method
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-23" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 23
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 23">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#temporal-difference-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Temporal-Difference Learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sarsa" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sarsa
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#q-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Q-Learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deep-q-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Deep Q-Learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#double-q-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Double Q-Learning
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-24" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 24
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 24">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#policy-gradient-methods" class="md-nav__link">
    <span class="md-ellipsis">
      
        Policy Gradient Methods
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dimensionality-reduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dimensionality Reduction
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dimensionality Reduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pca" class="md-nav__link">
    <span class="md-ellipsis">
      
        PCA
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-25" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 25
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 25">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#linear-discriminant-analysislda" class="md-nav__link">
    <span class="md-ellipsis">
      
        Linear Discriminant Analysis(LDA)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#manifold-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Manifold Learning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Manifold Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#isomap" class="md-nav__link">
    <span class="md-ellipsis">
      
        ISOMAP
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#locally-linear-embeddinglle" class="md-nav__link">
    <span class="md-ellipsis">
      
        Locally Linear Embedding(LLE)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#robust-pca" class="md-nav__link">
    <span class="md-ellipsis">
      
        Robust PCA
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autoencoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        AutoEncoder
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-26" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 26
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 26">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        Clustering
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Clustering">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        原型聚类
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        密度聚类
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        层次聚类
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature-selection" class="md-nav__link">
    <span class="md-ellipsis">
      
        feature selection
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="feature selection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        过滤式选择
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        包裹式选择
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        嵌入式选择
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse-encoding" class="md-nav__link">
    <span class="md-ellipsis">
      
        sparse encoding
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="sparse encoding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#compressive-sensing" class="md-nav__link">
    <span class="md-ellipsis">
      
        compressive sensing
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-27" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 27
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 27">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#semi-supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Semi-supervised learning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Semi-supervised learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        生成式方法
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#svm" class="md-nav__link">
    <span class="md-ellipsis">
      
        半监督SVM
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      
        图半监督学习
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#disagreement" class="md-nav__link">
    <span class="md-ellipsis">
      
        基于分歧disagreement的方法
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      
        半监督聚类
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-28" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lecture 28
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lecture 28">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      
        概率图模型
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="概率图模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hmm" class="md-nav__link">
    <span class="md-ellipsis">
      
        隐马尔可夫模型(HMM)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mrf" class="md-nav__link">
    <span class="md-ellipsis">
      
        马尔可夫随机场(MRF)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#crf" class="md-nav__link">
    <span class="md-ellipsis">
      
        条件随机场(CRF)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    <span class="md-ellipsis">
      
        学习与推断
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    <span class="md-ellipsis">
      
        近似推断
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#final-review" class="md-nav__link">
    <span class="md-ellipsis">
      
        Final Review
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/Tapir-Elithril/Notebook/edit/main/docs/fa25/ml/note.md" title="编辑此页" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  


<h1 id="machine-learning">机器学习(Machine Learning)<a class="headerlink" href="#machine-learning" title="Permanent link">&para;</a></h1>
<h2 id="lecture-1">Lecture 1<a class="headerlink" href="#lecture-1" title="Permanent link">&para;</a></h2>
<p>Machine learning is the study of computer systems that improve their performance through <strong>experience</strong>  </p>
<ul>
<li>supervised:regression/classification<br />
  input -&gt; specific label output  </li>
<li>unsupervised:clustering<br />
  input -&gt; ?  </li>
<li>reinforcement:react to an environment<br />
  input -&gt; reward maximization  </li>
</ul>
<h3 id="supervised-learning">Supervised learning<a class="headerlink" href="#supervised-learning" title="Permanent link">&para;</a></h3>
<p>Goal:learn a mapping from inputs <strong>x</strong> to outputs y<br />
training data:a labeled set of input-output pairs  </p>
<p>classification:y is a (discrete) categorical var<br />
regression:y is real-valued  </p>
<h3 id="unsupervised-learning">Unsupervised learning<a class="headerlink" href="#unsupervised-learning" title="Permanent link">&para;</a></h3>
<p>Goal:only given inputs and find "interesting patterns"  </p>
<p>clustering:discover clusters<br />
latent factors discovery:dimensionality reduction,matrix factorization(分解),topic modeling  </p>
<h3 id="reinforcement">Reinforcement<a class="headerlink" href="#reinforcement" title="Permanent link">&para;</a></h3>
<p>labels exist,learn how to act when given occasional reward or punishment signals  </p>
<p>final reward:win or lose<br />
credit assignment to a series of actions  </p>
<h2 id="lecture-2">Lecture 2<a class="headerlink" href="#lecture-2" title="Permanent link">&para;</a></h2>
<h3 id="supervised-learning-procedure">Supervised Learning Procedure<a class="headerlink" href="#supervised-learning-procedure" title="Permanent link">&para;</a></h3>
<p>Learning from experience(training data), and build model to predict the future<br />
Collect training samples(x,y) -&gt; step 1:define features(f,y) -&gt; step 2:design &amp; train model -&gt; make prediction<br />
end-to-end learning:training samples -&gt; Representation Learning(automatically get features) &amp; train -&gt; output<br />
general classification difficulty:intra-class variability &amp; inter-class similarity<br />
good representation/feature:low intra-class variability &amp; low inter-class similarity<br />
<img alt="alt text" src="../img/image.png" /><br />
classifier:t*<br />
two-dimensional feature space:linear decision boundary<br />
complex decision bounary:overfitting<br />
<img alt="alt text" src="../img/image-1.png" />  </p>
<div class="admonition danger">
<p class="admonition-title">在机器学习过程中，不断调整训练集的拟合程度在测试集上测试，直到达到在测试集上error最低❌，不可以根据测试集调参</p>
</div>
<p>测试集只能在所有决策完成之后做唯一的一次，测试集表现不佳只能在新的测试集上测试（e.g.高考与复读）  </p>
<h3 id="linear-methods-for-regression">Linear Methods for Regression<a class="headerlink" href="#linear-methods-for-regression" title="Permanent link">&para;</a></h3>
<p>learn a mapping from inputs <strong>x</strong> to outputs y,y is real-valued<br />
sample:<span class="arithmatex">\(\boldsymbol{x}=[x_1,...,x_d]^\top\)</span>,finds a linear function  <span class="arithmatex">\(\boldsymbol{w}=[w_1,...,w_d]^\top\)</span>,<span class="arithmatex">\(f(\boldsymbol{x})=\boldsymbol{w^\top x}+b\)</span><br />
Polynomial Curve Fitting:<span class="arithmatex">\(f(x,\boldsymbol{w})=w_0+w_1x+w_2x^2+...+w_Mx^M\)</span><br />
<span class="arithmatex">\(\boldsymbol{x}=[1,x,x^2,...,x^M]^\top,\boldsymbol{w}=[w_0,w_1,w_2,...,w_M]^\top,f(\boldsymbol{x},\boldsymbol{w})=\boldsymbol{w}^\top\boldsymbol{x}\)</span><br />
Sum-of-Square Error Function,<span class="arithmatex">\(MSE(\boldsymbol{w})=\frac{1}{n}\sum_{i=1}^n(y_i-f(x_i,\boldsymbol{w}))^2\)</span></p>
<h2 id="lecture-3">Lecture 3<a class="headerlink" href="#lecture-3" title="Permanent link">&para;</a></h2>
<p><span class="arithmatex">\(J_n=(\boldsymbol{y}-X^\top\boldsymbol{w})^\top(\boldsymbol{y}-X^\top\boldsymbol{w})\)</span><br />
<span class="arithmatex">\(\nabla J_n=-2X(\boldsymbol{y}-X^\top\boldsymbol{w}) = 0\)</span><br />
<span class="arithmatex">\(XX^\top\boldsymbol{w}=X\boldsymbol{y}\)</span><br />
<span class="arithmatex">\(\boldsymbol{w} = (XX^\top)^{-1}X\boldsymbol{y}\)</span><br />
note that <span class="arithmatex">\(XX^\top\)</span> have to be non-singular(非奇异，可逆)<br />
<span class="arithmatex">\(\hat{y}=X^\top\boldsymbol{a}=X^\top(XX^\top)^{-1}X\boldsymbol{y}\)</span>  </p>
<h3 id="statistical-model-of-regression-mle">Statistical model of regression —— MLE<a class="headerlink" href="#statistical-model-of-regression-mle" title="Permanent link">&para;</a></h3>
<p><span class="arithmatex">\(y=f(\boldsymbol{x},\boldsymbol{w})+\epsilon,\epsilon\)</span>~<span class="arithmatex">\(N(0,\sigma^2)\)</span><br />
...<br />
<span class="arithmatex">\(-(logL)' = -l' = RSS(f)=\sum_{i=1}^n(y_i-f(\boldsymbol{x}_i))^2 = MSE\)</span><br />
Linear regression is equivalent to MLE of generative model with Gaussian random noise  </p>
<h3 id="regularizationridge-regression">Regularization/Ridge Regression 岭回归<a class="headerlink" href="#regularizationridge-regression" title="Permanent link">&para;</a></h3>
<p>[Target] control the size of the coefficients<br />
<span class="arithmatex">\(\boldsymbol{w}^*=argmin\sum_{i=1}^n(y_i-\boldsymbol{x}_i^\top\boldsymbol{w})^2+\lambda\sum_{i=1}^pw_j^2\)</span><br />
<span class="arithmatex">\(\boldsymbol{w}^* = (XX^\top + \lambda\boldsymbol{I})^{-1}X\boldsymbol{y}\)</span><br />
note <span class="arithmatex">\(\boldsymbol{w}^*\)</span> must be non-singular<br />
<span class="arithmatex">\(\lambda=0,ln\lambda=-\infty \rightarrow linear\ regression\)</span><br />
<span class="arithmatex">\(ln\lambda=0 \rightarrow underfitting\)</span>  </p>
<h3 id="lassosparse-model">LASSO:sparse model<a class="headerlink" href="#lassosparse-model" title="Permanent link">&para;</a></h3>
<p>LASSO:Least Absolute Selection and Shrinkage Operator<br />
<span class="arithmatex">\(\boldsymbol{w}^*=argmin\frac{1}{2n}\sum_{i=1}^n(y_i-\boldsymbol{x}_i^\top\boldsymbol{w})^2\)</span>subject to<span class="arithmatex">\(\sum_{j=1}^p|w_j|\le t\)</span><br />
sparse:some parameters can be 0,efficient in calculation<br />
<img alt="alt text" src="../img/image-2.png" />  </p>
<h2 id="lecture-4">Lecture 4<a class="headerlink" href="#lecture-4" title="Permanent link">&para;</a></h2>
<h3 id="bias-variance-decomposition">Bias &amp; Variance Decomposition<a class="headerlink" href="#bias-variance-decomposition" title="Permanent link">&para;</a></h3>
<p>Loss:<span class="arithmatex">\(L(y,f(\boldsymbol{x}))\)</span><br />
Expected loss:<span class="arithmatex">\(E(L)=\int\int L(y,f(\boldsymbol{x}))p(\boldsymbol{x},y)d\boldsymbol{x}dy\)</span><br />
Squared loss:<span class="arithmatex">\(L(y,f(\boldsymbol{x}))=(y-f(\boldsymbol{x}))^2\)</span><br />
Expected Prediction Error:<span class="arithmatex">\(EPE(f)=\int\int (y-f(\boldsymbol{x}))^2p(\boldsymbol{x},y)d\boldsymbol{x}dy\)</span><br />
Find <span class="arithmatex">\(f(\boldsymbol{x^*})\)</span><br />
<span class="arithmatex">\((y-f(\boldsymbol{x})^2=(y-E(y|\boldsymbol{x})+E(y|\boldsymbol{x})-f(\boldsymbol{x}))^2= \\(y-E(y|\boldsymbol{x}))^2+(E(y|\boldsymbol{x})-f(\boldsymbol{x}))^2+2(y-E(y|\boldsymbol{x}))(E(y|\boldsymbol{x})-f(\boldsymbol{x}))\)</span><br />
<span class="arithmatex">\(EPE(f)=\int (f(\boldsymbol{x})-E(y|\boldsymbol{x}))^2p(\boldsymbol{x})d\boldsymbol{x}+\int var(y|\boldsymbol{x})p(\boldsymbol{x})d\boldsymbol{x}\)</span>(noise)<br />
In reality,we can never know the exact <span class="arithmatex">\(f(\boldsymbol{x})\)</span><br />
<span class="arithmatex">\(EPE(f)=\int (f(\boldsymbol{x};D)-E(y|\boldsymbol{x}))^2p(\boldsymbol{x})d\boldsymbol{x}+\int var(y|\boldsymbol{x})p(\boldsymbol{x})d\boldsymbol{x}\)</span><br />
<span class="arithmatex">\((f(\boldsymbol{x};D)-E(y|\boldsymbol{x}))^2=[f(\boldsymbol{x};D)-E_D(f(\boldsymbol{x};D))+E_D(f(\boldsymbol{x};D))-E(y|\boldsymbol{x})]^2\)</span><br />
<span class="arithmatex">\(EPE(f)=\int (E_D(f(\boldsymbol{x};D))-E(y|\boldsymbol{x}))^2p(\boldsymbol{x})d\boldsymbol{x}+\int E_D((f(\boldsymbol{x};D))-E_D(f(\boldsymbol{x};D)))^2)p(\boldsymbol{x})d\boldsymbol{x}+\int var(y|\boldsymbol{x})p(\boldsymbol{x})d\boldsymbol{x}=(bias)^2+variance+noise\)</span><br />
variance:<span class="arithmatex">\(E_D((f(\boldsymbol{x};D))-E_D(f(\boldsymbol{x};D)))^2)\)</span> caused by different datasets<br />
bias²:<span class="arithmatex">\((E_D(f(\boldsymbol{x};D))-E(y|\boldsymbol{x}))^2\)</span> difference between the calculated distribution and the ground truth<br />
noise:<span class="arithmatex">\(var(y|\boldsymbol{x})p(\boldsymbol{x})d\boldsymbol{x}\)</span> caused by the real distribution(e.g. an x corresponds to many y),irreducible <br />
<img alt="alt text" src="../img/image-3.png" /><br />
<img alt="alt text" src="../img/image-4.png" /><br />
variance:sensitivity to dataset  </p>
<h4 id="the-bias-variance-trade-off">The Bias-Variance Trade-off<a class="headerlink" href="#the-bias-variance-trade-off" title="Permanent link">&para;</a></h4>
<p>large <span class="arithmatex">\(\lambda\)</span> -&gt; over-regularized -&gt; high bias<br />
small <span class="arithmatex">\(\lambda\)</span> -&gt; under-regularized -&gt; high variance<br />
<img alt="alt text" src="../img/image-5.png" />  </p>
<h3 id="cross-validation">Cross-Validation<a class="headerlink" href="#cross-validation" title="Permanent link">&para;</a></h3>
<p>K-fold Cross-Validation + average/vote,leave-one-out validation  </p>
<h3 id="classification">Classification<a class="headerlink" href="#classification" title="Permanent link">&para;</a></h3>
<p>discriminant function:<span class="arithmatex">\(g_i(\boldsymbol{x})\)</span>,classifier assign a feature vector <span class="arithmatex">\(\boldsymbol{x}\)</span> to class <span class="arithmatex">\(\omega_i\)</span> if <span class="arithmatex">\(g_i(\boldsymbol{x}) &gt; g_j(\boldsymbol{x}),\forall j \neq i\)</span>  </p>
<h4 id="binary-classifier-to-multi-class-classifier">Binary Classifier to Multi-class Classifier<a class="headerlink" href="#binary-classifier-to-multi-class-classifier" title="Permanent link">&para;</a></h4>
<ul>
<li>One vs Rest:依据多个one分类器（如猫分类器，狗分类器，鸟分类器）的结果与置信度判断    </li>
<li>One vs One:每两个类别作为一个分类器（如猫狗分类器，猫鸟分类器，狗鸟分类器），将每个的结果与置信度判断  </li>
<li>ECOC(Error-Correcting Output Codes):多分类问题转化为多个二分类问题  </li>
</ul>
<h4 id="regression-to-classification">Regression to Classification<a class="headerlink" href="#regression-to-classification" title="Permanent link">&para;</a></h4>
<p>Linear regression:<span class="arithmatex">\(f(\boldsymbol{x})=\boldsymbol{w}^\top\boldsymbol{x}\in(-\infty,+\infty)\)</span><br />
classfication:Estimate <span class="arithmatex">\(P(\omega|x)\in\left\{0,1,-1\right\}\)</span><br />
sigmoid function/logistic function:<span class="arithmatex">\(\sigma(t)=\frac{1}{1+e^{-t}}\)</span>,<span class="arithmatex">\(\sigma:\mathbb{R}\rightarrow(0,1)\)</span><br />
Logistic Regression:a classification model using sigmoid function<br />
<span class="arithmatex">\(P(y_i=\pm 1|\boldsymbol{x}_i,\boldsymbol{a})=\sigma(y_i\boldsymbol{a}^\top\boldsymbol{x}_i)=\frac{1}{1+e^{-y_i\boldsymbol{a}^\top\boldsymbol{x}_i}}\)</span><br />
MLE:<span class="arithmatex">\(P(D)=\Pi\sigma(y_i\boldsymbol{a}^\top\boldsymbol{x}_i)\)</span><br />
<span class="arithmatex">\(l(P(D))=-\sum\log(1+e^{-y_i\boldsymbol{a}^\top\boldsymbol{x}_i})\)</span><br />
<span class="arithmatex">\(E(\boldsymbol{a})=\sum\log(1+e^{-y_i\boldsymbol{a}^\top\boldsymbol{x}_i})\)</span>,target of minimum optimization<br />
Using <strong>Gradient Descent</strong>  </p>
<h2 id="lecture-5">Lecture 5<a class="headerlink" href="#lecture-5" title="Permanent link">&para;</a></h2>
<h3 id="gradient-descent">Gradient Descent<a class="headerlink" href="#gradient-descent" title="Permanent link">&para;</a></h3>
<p>first-order iterative optimization -&gt; local minimum<br />
<span class="arithmatex">\(J(w)\)</span> is defined and differentiable in a neighbourhood of <span class="arithmatex">\(a\)</span>,let <span class="arithmatex">\(b=a-\gamma\nabla J(a)\)</span>,for<span class="arithmatex">\(\gamma\)</span> small enough,<span class="arithmatex">\(J(a)\ge J(b)\)</span><br />
<span class="arithmatex">\(w_{n+1}=w_n-\gamma \nabla J(w_n),n\ge 0\)</span>,hopefully the sequence <span class="arithmatex">\(w_n\)</span> converges to the desired local minimum<br />
Zig-zagging nature<br />
Newton's Method(second-order):Minimize <span class="arithmatex">\(E'(a)\Delta a+E''(a)\frac{\Delta a^2}{2!}\)</span>  </p>
<div class="admonition note">
<p class="admonition-title">more details in Introductory Lectures on Optimization</p>
</div>
<h3 id="support-vector-machine">Support Vector Machine<a class="headerlink" href="#support-vector-machine" title="Permanent link">&para;</a></h3>
<h4 id="geometrical-margin">Geometrical margin<a class="headerlink" href="#geometrical-margin" title="Permanent link">&para;</a></h4>
<p>two-category linearly separable case:<span class="arithmatex">\(w^\top x&gt;0\rightarrow positive \ class,&lt;0 \rightarrow negative\)</span><br />
<span class="arithmatex">\(w\)</span>:separating vector<br />
<img alt="alt text" src="../img/image-6.png" /><br />
non-uniqueness hyperplane classifier,which one is better?<br />
linear model:<span class="arithmatex">\(f(x)=w^\top x + b = 0\)</span><br />
distance of point <span class="arithmatex">\(x\)</span> to hyperplane<br />
<span class="arithmatex">\(f(x_p)=w^\top(x-r\frac{w}{||w||})+b=0\)</span><br />
<span class="arithmatex">\(f(x)=w^\top x+b=r||w||\)</span><br />
<span class="arithmatex">\(r=\frac{f(x)}{||w||}\)</span><br />
<span class="arithmatex">\(\gamma = y\cdot r,y=-1 \ if \ r&lt;0\)</span> make it non-negative<br />
<span class="arithmatex">\(\gamma\)</span> is called geometrical margin<br />
<span class="arithmatex">\(\gamma = y\frac{w^\top x+b}{||w||}\)</span>,if the hyperplane moves a little,points with small <span class="arithmatex">\(\gamma\)</span> is likely to be affected    </p>
<h4 id="maximum-margin-classifier">Maximum Margin Classifier<a class="headerlink" href="#maximum-margin-classifier" title="Permanent link">&para;</a></h4>
<p>margin of a dataset:minimum margin for each data point<br />
[goal] find the hyperplane with the largest margin<br />
<span class="arithmatex">\(max_{w,b}\gamma=max_{w,b}\frac{y(w^\top x+b)}{||w||},s.t.\gamma_i\ge\gamma\)</span><br />
fixing <span class="arithmatex">\(y(w^\top x+b) = 1\)</span> to avoid making it arbitrarily large<br />
<span class="arithmatex">\(max_{w,b}\frac{y(w^\top x+b)}{||w||}=max_{w,b}\frac{1}{||w||}=min_{w,b}||w||\iff min_{w,b}\frac{1}{2}||w||^2 \\ s.t.,\gamma_i=\frac{y_i(w^\top x_i+b)}{||w||}\ge \gamma \iff y_i(w^\top x_i+b)\ge\gamma||w||=1\iff y_i(w^\top x_i+b)\ge1\)</span><br />
[Definition] loss function of MMC:<span class="arithmatex">\(min_{w,b}\frac{1}{2}||w||^2,s.t.,y_i(w^\top x_i+b)\ge1\)</span><br />
<span class="arithmatex">\(y_i\in\left\{1,-1\right\}\)</span>  </p>
<h4 id="support-vector">Support Vector<a class="headerlink" href="#support-vector" title="Permanent link">&para;</a></h4>
<p>[Definition] the points on the margin supporting the hyperplane<br />
<img alt="alt text" src="../img/image-7.png" /><br />
weakness:outlier pushes the hyperplane away from the original place(<strong>overfitting</strong>)<br />
slack variables<span class="arithmatex">\(\xi\)</span>:allow the point to deviate the correct margin(even be classified wrongly) by distance <span class="arithmatex">\(\xi\)</span><br />
<img alt="alt text" src="../img/image-8.png" /><br />
new objective function:<span class="arithmatex">\(min_{w,b,\xi}\frac{1}{2}||w||^2+c\sum_{i=1}^n\xi_i,s.t.,y_i(w^\top x_i+b)\ge1-\xi_i,\xi_i\ge0\)</span><br />
<span class="arithmatex">\(c\)</span>表示违背约束的惩罚系数，很大时(<span class="arithmatex">\(\xi\)</span>很小时)退化为传统MMC  </p>
<h2 id="lecture-6">Lecture 6<a class="headerlink" href="#lecture-6" title="Permanent link">&para;</a></h2>
<h3 id="lagrange-multipliers-and-the-karush-kuhn-tucker-conditions">Lagrange Multipliers and the Karush-Kuhn-Tucker conditions<a class="headerlink" href="#lagrange-multipliers-and-the-karush-kuhn-tucker-conditions" title="Permanent link">&para;</a></h3>
<h4 id="unconstrained-optimization">Unconstrained Optimization<a class="headerlink" href="#unconstrained-optimization" title="Permanent link">&para;</a></h4>
<p>1.<span class="arithmatex">\(f\)</span> has zero gradient at <span class="arithmatex">\(x^*\)</span>:<span class="arithmatex">\(\nabla_xf(x^*)=0\)</span><br />
2.The Hessian of <span class="arithmatex">\(f\)</span> at <span class="arithmatex">\(x^*\)</span> is positive semi-definite:<br />
$$
\nabla^2f(x)=\begin{pmatrix}
\frac{\partial^2f(x)}{\partial x_1^2} &amp; ... &amp; \frac{\partial^2f(x)}{\partial x_1\partial x_n} \ ... &amp; ...&amp; ... \\frac{\partial^2f(x)}{\partial x_n\partial x_1}&amp;...&amp;\frac{\partial^2f(x)}{\partial x_n^2}
\end{pmatrix}
$$  </p>
<h4 id="constrained-optimizationequality-constraints">Constrained Optimization:Equality Constraints<a class="headerlink" href="#constrained-optimizationequality-constraints" title="Permanent link">&para;</a></h4>
<p><span class="arithmatex">\(min f(x),s.t.h(x)=0\)</span><br />
<span class="arithmatex">\(e.g.minf(x)=x_1+x_2,s.t.h(x)=x_1^2+x_2^2-2=0\)</span><br />
<img alt="alt text" src="../img/image-9.png" /><br />
Given a feasible point <span class="arithmatex">\(x_F\)</span> on the constraint surface<br />
Find <span class="arithmatex">\(\delta x,s.t.h(x_F+\alpha\delta x)=0 and f(x_F+\alpha\delta x)&lt;f(x_F)\)</span><br />
At any point <span class="arithmatex">\(\tilde{x}\)</span>,the direction of the steepest descent of the cost function <span class="arithmatex">\(f(x)\)</span> is given by <span class="arithmatex">\(-\nabla_x f(\tilde{x})\)</span><br />
Therefore,to move <span class="arithmatex">\(\delta x\)</span> from <span class="arithmatex">\(x\)</span> such that <span class="arithmatex">\(f(x+\delta x)&lt;f(x)\)</span> must have <span class="arithmatex">\(\delta x\cdot(-\nabla_x f(x))&gt;0\)</span> <br />
<img alt="alt text" src="../img/image-10.png" /><br />
Also,to move a small <span class="arithmatex">\(\delta x\)</span> from <span class="arithmatex">\(x\)</span> and remain on the constraint surface fastest,we have to move orthogonal to <span class="arithmatex">\(\nabla_x h(x)\)</span><br />
<strong>When <span class="arithmatex">\(\nabla_x f(x_F)=\mu\nabla_x h(x_F)\)</span>,then <span class="arithmatex">\(\delta x\cdot(-\nabla_x f(x))=\delta x\cdot \mu\nabla_x h(x_F)=0\)</span>,then we reach the local optimum</strong>  </p>
<h4 id="lagrange-multiplier">Lagrange Multiplier<a class="headerlink" href="#lagrange-multiplier" title="Permanent link">&para;</a></h4>
<p><span class="arithmatex">\(min f(x),s.t.h(x)=0\)</span><br />
Lagrangian:<span class="arithmatex">\(\mathcal{L}(x,\mu)=f(x)+\mu h(x)\)</span><br />
<span class="arithmatex">\(\mathcal{L}(x^*,\mu^*)=f(x^*)\)</span><br />
<span class="arithmatex">\(x^*\)</span> is a local minimum <span class="arithmatex">\(\iff\)</span> there exists a unique <span class="arithmatex">\(\mu^*\)</span> s.t. <br />
1.<span class="arithmatex">\(\nabla_x\mathcal{L}(x^*,\mu^*)=0(\nabla_x f(x^*)=\mu^*\nabla_x h(x^*))\)</span><br />
2.<span class="arithmatex">\(\nabla_\mu\mathcal{L}(x^*,\mu^*)=0(h(x^*)=0)\)</span><br />
3.<span class="arithmatex">\(y^\top(\nabla_{xx}\mathcal{L}(x^*,\mu^*))y\ge0,\forall y,s.t.\nabla_x h(x^*)^\top y =0\)</span><br />
multiple equality constraints:<span class="arithmatex">\(\mathcal{L}(x,\mu)=f(x)+\sum_i\mu_i h_i(x)\)</span>  </p>
<h4 id="constrained-optimizationinequality-constraints">Constrained Optimization:Inequality Constraints<a class="headerlink" href="#constrained-optimizationinequality-constraints" title="Permanent link">&para;</a></h4>
<p><span class="arithmatex">\(min f(x)=x_1^2+x_2^2,s.t.g(x)=x_1^2+x_2^2-1\le0\)</span><br />
case1(inactive constraint):unconstrained minimum of <span class="arithmatex">\(f\)</span> lies in the feasible region<br />
case2(active constraint):<span class="arithmatex">\(min f(x)=(x_1-1.1)^2+(x_2-1.1)^2,s.t.g(x)=x_1^2+x_2^2-1\le0\)</span><br />
<img alt="alt text" src="../img/image-11.png" /><br />
The constrained local minimum occurs on the surface of the constraint surface <span class="arithmatex">\(g(x)=0\)</span><br />
<strong><span class="arithmatex">\(-\nabla_x f(x)=\lambda\nabla_x g(x),\lambda &gt;0\)</span></strong>,pointing the central of the feasible region<br />
Remember,<span class="arithmatex">\(y^\top\nabla_{xx}\mathcal{L}(x^*)y\ge0,\forall y,s.t.\nabla_x g(x^*)^\top y =0\)</span>  </p>
<h4 id="kkt-conditions">*KKT conditions<a class="headerlink" href="#kkt-conditions" title="Permanent link">&para;</a></h4>
<p><img alt="alt text" src="../img/image-12.png" />  </p>
<h3 id="python-basic">Python Basic<a class="headerlink" href="#python-basic" title="Permanent link">&para;</a></h3>
<h2 id="lecture-7">Lecture 7<a class="headerlink" href="#lecture-7" title="Permanent link">&para;</a></h2>
<h3 id="generalized-linear-function">Generalized Linear Function<a class="headerlink" href="#generalized-linear-function" title="Permanent link">&para;</a></h3>
<p>[Problem] Circles are difficult to separate by a hyperplane<br />
[Solution] Add a dimension(feature)<br />
<span class="arithmatex">\((x_1,x_2)\rightarrow(x_1,x_2,x_1^2+x_2^2)\)</span><br />
<span class="arithmatex">\(g(x)=\sum_{i=1}^d w_ix_i+w_0\)</span><br />
generalized linear discriminant:<span class="arithmatex">\([x_1,x_2,x_3]\rightarrow[x_1,x_2,x_3,x_1x_2,x_1x_3,x_2x_3,x_1x_2x_3]\)</span><br />
<span class="arithmatex">\(y_i(x)\)</span>:polynomial discriminant functions<br />
<span class="arithmatex">\(y=[y_1(x),...,y_d(x)]^t\)</span>:augmented feature vector<br />
The mapping <span class="arithmatex">\(y\)</span> is called the phi function <span class="arithmatex">\(x\rightarrow \phi(x)\)</span><br />
non-practical explicit form,curse of dimensionality维数灾难  </p>
<h3 id="kernel-method">Kernel Method<a class="headerlink" href="#kernel-method" title="Permanent link">&para;</a></h3>
<p>[Idea] Use kernel functions to compute inner products implicitly,thereby preventing the curse of dimensionality<br />
<span class="arithmatex">\(k(x,x')\rightarrow \phi(x)^\top\phi(x')\)</span><br />
kernel function <span class="arithmatex">\(k,k(x,x')=k(x',x)\)</span>,similarity measurement:<span class="arithmatex">\(k(x,x')\ge 0,x,x'\in\mathcal{X}\)</span>(Mercer定理)<br />
Dual representation:ridge regression<br />
primal and dual(原始问题与对偶问题)<br />
<span class="arithmatex">\(J(w)=\frac{1}{2}\sum_{i=1}^N(w^\top x_i-t_i)^2+\frac{\lambda}{2}w^\top w\)</span><br />
<span class="arithmatex">\(\frac{\partial J}{\partial w} = 0 \Rightarrow w = \sum_{i=1}^Na_i\phi(x_i)=\Phi^\top a\)</span><br />
<span class="arithmatex">\(\Phi=[\phi(x_1),...,\phi(x_N)]^\top\)</span><br />
<span class="arithmatex">\(b=[w^\top\phi(x_1),...,w^\top\phi(x_N)]^\top,t=[t_1,...,t_N]^\top\)</span><br />
<span class="arithmatex">\(J(w)=\frac{1}{2}(b-t)^\top(b-t)+\frac{\lambda}{2}w^\top w\)</span><br />
<span class="arithmatex">\(b^\top=a^\top \Phi\Phi^\top\)</span><br />
<span class="arithmatex">\(J(a)=\frac{1}{2}a^\top\Phi\Phi^\top\Phi\Phi^\top a-a^\top\Phi\Phi^\top t+\frac{1}{2}t^\top t+\frac{\lambda}{2}a^\top\Phi\Phi^\top a\)</span><br />
Gram matrix:<span class="arithmatex">\(K = \Phi\Phi^\top,K_{nm}=k(x_n,x_m)\)</span><br />
<span class="arithmatex">\(a^*=(K+\lambda I)^{-1}t\)</span><br />
<span class="arithmatex">\(y(x)=w^\top\phi(x)=k(x)^\top(K+\lambda I)^{-1}t\)</span><br />
即当满足Mercer定理时，新特征<span class="arithmatex">\(\phi(x)\)</span>总是能由对应的核函数(某种内积)来表达，从而简便计算避免升维<br />
事实上，给定满足条件的核函数后，我们就不需要关心特征函数的形式  </p>
<h4 id="maximum-margin-classifier_1">Maximum Margin Classifier<a class="headerlink" href="#maximum-margin-classifier_1" title="Permanent link">&para;</a></h4>
<p><span class="arithmatex">\(\mathcal{L}(w,b,a)=\frac{1}{2}||w||^2-\sum_{i=1}^Na_i(y_i(w^\top \phi(x_i)+b)-1)\)</span><br />
<span class="arithmatex">\(w=\sum_{i=1}^Na_iy_i\phi(x_i)\)</span><br />
<span class="arithmatex">\(\mathcal{L}(a)=\frac{1}{2}\sum_{i=1}^N\sum_{j=1}^Na_ia_jy_iy_j\phi^\top(x_i)\phi(x_j)+\sum_{i=1}^Na_i,\sum_{i=1}^Na_iy_i=0\)</span><br />
hyperplane:<span class="arithmatex">\(f(x)=w^\top\phi(x)+b=\sum_{i=1}^Na_iy_i\phi(x_i)^\top\phi(x)+b\)</span>  </p>
<h4 id="common-kernel-functions">Common Kernel Functions<a class="headerlink" href="#common-kernel-functions" title="Permanent link">&para;</a></h4>
<p>Linear:<span class="arithmatex">\(k(x,x')=x^\top x'\)</span><br />
Polynomial:<span class="arithmatex">\(k(x,x')=(x^\top x'+1)^d\)</span><br />
RBF:<span class="arithmatex">\(k(x,x')=exp(-\frac{||x-x'||^2}{2\sigma^2})\)</span>(likely get overfitting)  </p>
<h3 id="decision-tree">Decision Tree<a class="headerlink" href="#decision-tree" title="Permanent link">&para;</a></h3>
<p>[Definition] A hierarchical data structure that represents data by implementing a divide and conquer strategy<br />
<img alt="alt text" src="../img/image-13.png" />  </p>
<h2 id="lecture-8">Lecture 8<a class="headerlink" href="#lecture-8" title="Permanent link">&para;</a></h2>
<p>How many trees we can build? <span class="arithmatex">\(n!\)</span><br />
Some trees are better than others? A small tree is better<br />
A smaller tree is faster to search while better at generalization<br />
<span class="arithmatex">\(EPE(f)=(bias)^2+variance+noise\)</span><br />
The deeper the tree is,the more likely it will be overfitting<br />
However,finding the minimal decision tree consistent with the data is NP-hard  </p>
<h3 id="picking-the-best-feature">Picking the best feature<a class="headerlink" href="#picking-the-best-feature" title="Permanent link">&para;</a></h3>
<p><span class="arithmatex">\(&lt;A=0,B=0&gt;-:50 \\ &lt;A=0,B=1&gt;-:50 \\&lt;A=1,B=0&gt;-:0 \\&lt;A=1,B=1&gt;+:100\)</span><br />
spliting on A:purely labeled<br />
<span class="arithmatex">\(&lt;A=0,B=0&gt;-:50 \\ &lt;A=0,B=1&gt;-:50 \\&lt;A=1,B=0&gt;-:3 \\&lt;A=1,B=1&gt;+:100\)</span><br />
first spliting on which is better?<br />
ID3:we want attributes that split the examples to sets are relatively pure in one label;this way we are closer to a leaf node<br />
<img alt="alt text" src="../img/image-14.png" /><br />
entropy:<span class="arithmatex">\(Entropy(S)=-P_+\log P_+-P_-\log P_-\)</span><br />
<span class="arithmatex">\(P_+=1(P_-=1),Entropy=0\)</span><br />
<span class="arithmatex">\(P_+=P_-=0.5,Entropy=1\)</span><br />
multi-classification:<span class="arithmatex">\(Entropy(S)=-\sum_{i=1}^cP_i\log P_i\)</span><br />
Entropy measures the level of uncertainty<br />
we can pick the feature that the resulting data partition has low entropy<br />
Information Gain:<span class="arithmatex">\(Gain(S,n)=Entropy(S)-\sum_{v\in values(a)}\frac{|S_v|}{|S|}Entropy(S_v)\)</span>,经过决策树选择后熵的差值<br />
partitions of low entropy leads to high gain<br />
[Example] PlayTennis?<br />
9+,5- <span class="arithmatex">\(Entropy(S)=-\frac{9}{14}\log\frac{9}{14}-\frac{5}{14}\log\frac{5}{14}=0.94\)</span><br />
<span class="arithmatex">\(a\in\left\{humidity,wind\right\}\)</span><br />
<img alt="alt text" src="../img/image-15.png" /><br />
avoid overfitting:prepruning(stop growing at some point),postpruning(remove nodes without sufficient evidence,too small information gain)  </p>
<h3 id="cartclassification-and-regression-trees">CART(Classification and Regression Trees)<a class="headerlink" href="#cartclassification-and-regression-trees" title="Permanent link">&para;</a></h3>
<p>ID3 can be only used for classification and the features must be discrete<br />
solution:partition the input space into several regions,and let each region output the same constant<br />
note that a feature can be used more than once<br />
<img alt="" src="../img/image-16.png" /><br />
<span class="arithmatex">\(f(x)=\sum_{\tau=1}^M c_{\tau}I(x\in \mathcal{R}_{\tau})\)</span><br />
<span class="arithmatex">\(c_{\tau}=\frac{1}{N_{\tau}}\sum_{x_i\in\mathcal{R}_{\tau}}y_i\)</span><br />
<span class="arithmatex">\(Q_{\tau}(T)=\sum_{x_i\in\mathcal{R}}(y_i-c_{\tau})^2\)</span><br />
build the tree:greedy solution<br />
how to pick the feature and threshold?<br />
pick feature <span class="arithmatex">\(x^{(j)}\)</span> and <span class="arithmatex">\(s\)</span> as the spliting point,we have two regions:<span class="arithmatex">\(\mathcal{R}_1(j,s)=\left\{\bold{x}|x^{(j)}\leq s\right\},\mathcal{R}_2(j,s)=\left\{\bold{x}|x^{(j)}&gt; s\right\}\)</span><br />
<span class="arithmatex">\(\underset{j,s}{min}[\underset{c_1}{min}\sum_{x_i\in\mathcal{R}_1(j,s)}(y_i-c_1)^2+\underset{c_2}{min}\sum_{x_i\in\mathcal{R}_2(j,s)}(y_i-c_2)^2]\)</span>  </p>
<h2 id="lecture-9">Lecture 9<a class="headerlink" href="#lecture-9" title="Permanent link">&para;</a></h2>
<h4 id="when-to-stop">when to stop?<a class="headerlink" href="#when-to-stop" title="Permanent link">&para;</a></h4>
<p>the reduction in residual error falls below some threshold<br />
none of the avaliable splits produces a significant reduction in error  </p>
<h4 id="how-to-prune">how to prune?<a class="headerlink" href="#how-to-prune" title="Permanent link">&para;</a></h4>
<p>pruning criterion:<span class="arithmatex">\(C(T)=\sum_{T=1}^{|T|}Q_{\tau}(T)+\lambda |T|\)</span><br />
<span class="arithmatex">\(\lambda\)</span> determines the trade-off between the overall residual sum-of-squares error and the complexity of the model(<span class="arithmatex">\(|T|\)</span> represents the number of leaf nodes),the value is chosen by cross-validation  </p>
<h4 id="cart-for-classification">CART for classification<a class="headerlink" href="#cart-for-classification" title="Permanent link">&para;</a></h4>
<p>use entropy or Gini index instead of residual sum-of-squares<br />
<span class="arithmatex">\(Q_{\tau}(T)=\sum_{k=1}^Kp_{\tau k}\log p_{\tau k}\)</span>  </p>
<h3 id="artificial-neural-network-deep-learning">Artificial Neural Network &amp; Deep Learning<a class="headerlink" href="#artificial-neural-network-deep-learning" title="Permanent link">&para;</a></h3>
<p>we move further than perceptron,define feature is no longer reliable<br />
SIFT -&gt; ImageNet competition(top-5 error:predict 5 labels,any one of the 5 labels is correct,then the prediction is correct) -&gt; AlexNet<br />
Neural Network,NN;Artificial Neural Network,ANN<br />
Linear model(classifier):<span class="arithmatex">\(f(x)=w^Tx+b\)</span><br />
<img alt="" src="../img/image-17.png" />  </p>
<h4 id="perceptron">perceptron<a class="headerlink" href="#perceptron" title="Permanent link">&para;</a></h4>
<p>If model predict <span class="arithmatex">\(x\)</span> correct,do nothing<br />
else,multiply <span class="arithmatex">\(x\)</span> by its label,let <span class="arithmatex">\(w_t=w_{t-1}+xy\)</span><br />
because if <span class="arithmatex">\(w\)</span> is a solution,for any <span class="arithmatex">\(x\)</span> in training set,<span class="arithmatex">\(w^Txy&gt;0\)</span><br />
drawback:only capable of learning linearly separable functions<br />
e.g.Logical OR gate:input<span class="arithmatex">\((x_1,x_2)\)</span>,weight <span class="arithmatex">\(w_0=0.5\)</span> for <span class="arithmatex">\(x_0\)</span>,<span class="arithmatex">\(f(x)=x_1+x_2+0.5\)</span><br />
Logical AND gate:<span class="arithmatex">\(f(x)=x_1+x_2-1.5\)</span><br />
XOR gate is impossible to be solved by a perceptron<br />
"The first AI winter"(1969)<br />
[Solution] multi-layer perceptrons(hidden layer)<br />
define a criterion function(loss function),then optimize the function<br />
If the model predicts wrongly,put the penalty <span class="arithmatex">\(r=\frac{f(x)}{||w||},J(w)=-\sum_{i\in I_M}w^Tx_iy_i\)</span>,proportional to the sum of distances from misclassified samples to the decision boundary<br />
gradient descent:<span class="arithmatex">\(\nabla J=\sum_{i\in I_M}-x_iy_i\)</span><br />
start from <span class="arithmatex">\(w=0\)</span>,<span class="arithmatex">\(w(k+1)=w(k)+\eta(k)\sum_{i\in I^k_M}x_iy_i\)</span>,where <span class="arithmatex">\(\eta\)</span> is the learning rate  </p>
<h2 id="lecture-10">Lecture 10<a class="headerlink" href="#lecture-10" title="Permanent link">&para;</a></h2>
<p>batch learning:all samples are avaliable<br />
online learning/mini-batch learning:see samples one by one,faster and lower memory cost  </p>
<h3 id="backpropagation">Backpropagation<a class="headerlink" href="#backpropagation" title="Permanent link">&para;</a></h3>
<p>compute the weight<br />
<img alt="" src="../img/image-18.png" /><br />
forward:<span class="arithmatex">\(z_k=f(\sum_j w_{kj}f(\sum_i w_{ji}x_i+w_{j0})+w_{k0})\)</span><br />
penalty:<span class="arithmatex">\(J\)</span><br />
backward:<span class="arithmatex">\(\Delta w=-\eta\nabla J=-\eta\frac{\partial J}{\partial w},\eta:learning\ rate\)</span><br />
<span class="arithmatex">\(w^{(t+1)}=w^{(t)}+\Delta w^{(t)}\)</span><br />
<span class="arithmatex">\(J=\frac{1}{2}\sum_{i=1}^c(t_k-z_k)^2\)</span><br />
<span class="arithmatex">\(net_j=\sum_{j=0}^dx_iw_{ji},net_k=\sum_{j=0}^{n_H}y_jw_{kj}\)</span><br />
<span class="arithmatex">\(\frac{\partial J}{\partial w_{kj}}=\frac{\partial J}{\partial z_k}\cdot\frac{\partial z_k}{\partial net_k}\cdot\frac{\partial net_k}{\partial w_{kj}}=(z_k-t_k)\cdot f'(net_k)\cdot y_j \\ \frac{\partial J}{\partial w_{ji}}=(\sum_{k=1}^c(z_k-t_k)\cdot f'(net_k)\cdot y_j)\cdot f'(net_j)\cdot x_i\)</span><br />
<span class="arithmatex">\(n_H\)</span>:number of hidden units,more complicated nonlinear functions<br />
[Kolmogorov] Any continuous function can be implemented in a three-layer net with sufficient number of <span class="arithmatex">\(n_H\)</span>,proper nonlinearities(activation function) and weights<br />
<span class="arithmatex">\(n_H=2n+1\)</span> </p>
<h3 id="neural-net-models">Neural Net models<a class="headerlink" href="#neural-net-models" title="Permanent link">&para;</a></h3>
<p>Net topology,Node(processor) characteristic,optimization rules<br />
"The second AI winter"(1997):SVM &gt; neural network<br />
CIFAR<br />
why not go deeper?<br />
vanishing gradient,expensive computation,no need(SVM,MNIST:0.56%)<br />
2006:pre-train<br />
2007:GPU<br />
2009:ImageNet<br />
Because the nueral networks are too expressive,the more training data you feed,the less prone to overfitting the neural network will be.  </p>
<h3 id="activation-function">Activation Function<a class="headerlink" href="#activation-function" title="Permanent link">&para;</a></h3>
<p>If no <span class="arithmatex">\(f\)</span>,the neural network degrade to one-level,<span class="arithmatex">\(f\)</span> must be some nonlinear operation  </p>
<h2 id="lecture-11">Lecture 11<a class="headerlink" href="#lecture-11" title="Permanent link">&para;</a></h2>
<p>Lab(numpy)  </p>
<h2 id="lecture-12">Lecture 12<a class="headerlink" href="#lecture-12" title="Permanent link">&para;</a></h2>
<h3 id="quiz">quiz<a class="headerlink" href="#quiz" title="Permanent link">&para;</a></h3>
<p><img alt="" src="../img/image-19.png" /><br />
<span class="arithmatex">\(f\)</span> must be non-linear and saturate(have max/min bound),activation function and its derivative must be continuous and smooth;optimally monotonic  </p>
<ul>
<li>sigmoid:<span class="arithmatex">\(\sigma(x)=\frac{1}{1+e^{-x}}\)</span>  </li>
<li>tanh:<span class="arithmatex">\(t(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}=2\sigma(2x)-1\)</span>,rescaled and shifted sigmoid for better gradient performance  </li>
</ul>
<p><strong>vanishing gradient</strong>:<span class="arithmatex">\(f'(net_4)*f'(net_3)*f'(net_2)*f'(net_1)\rightarrow 0,f'(net_i)&lt;1\)</span><br />
[Solution] RevoLUtion/Rectified Linear Unit:<span class="arithmatex">\(ReLU(x)=max(0,x)\)</span><br />
Spare representation:half of neurons are silence<br />
[Problem] overfitting<br />
[Solution] dropout:in every iteration,every neuron has a chance <span class="arithmatex">\(p\)</span> to be ignored,acting as if it is dead or does not exist.And during the test phase,all nodes all activated    </p>
<h2 id="lecture-13">Lecture 13<a class="headerlink" href="#lecture-13" title="Permanent link">&para;</a></h2>
<h3 id="net-topology-cnn">Net topology &amp; CNN<a class="headerlink" href="#net-topology-cnn" title="Permanent link">&para;</a></h3>
<p>images -&gt; too many parameters<br />
e.g. using a fully connected network to solve 200 * 200 images,40000 units in first hidden layer,we need <span class="arithmatex">\(200^4=1.6\ billion\)</span> parameters<br />
[Solution] Convolutional Neural Network(CNN)<br />
hidden units are only connected to local receptive field(convolution kernel)<br />
<img alt="" src="../img/image-20.png" /><br />
Convolution:more in Introduction to Computer Vision<br />
weight share:the parameters in the kernel are same when scanning the whole picture<br />
e.g.32 * 32 * 3 image using 5 * 5 * 3 filter,we get a 28 * 28 * 1 activation map<br />
we use 6 such filters,we get 28 * 28 * 6 map<br />
ConvNet is a sequence of convolutional layers,interspersed with activation functions<br />
<img alt="" src="../img/image-21.png" /><br />
Because weight is shared,gradient is shared too<br />
stride:step size<br />
Receptive field感受野:a pixel containes the information of how many pixels in input<br />
e.g.3 * 3kernel,the receptive field is 3 * 3,then apply another 3 * 3kernel,the receptive field becomes 5 * 5<br />
large receptive field can be achieved by deeper layer,convolution with larger stride and pooling layers<br />
layer close to input:small receptive fields,simple<br />
layer close to output:large receptive fields,complex feature,more semantic information<br />
FC layer:3D tensor -&gt; vector<br />
pooling:max pool,average pool<br />
pooling layer makes the representations smaller and more manageable,operates over each activation map independently<br />
LeNet-5:the first successful application of CNN(for check validation)<br />
AlexNet:The first work that popularized CNN in the field of CV with 60M parameters<br />
softmax:normalization<br />
ZFNet:using deconvnet to reconstruct an approximate version of the convnet features from the layer beneath<br />
VGGNet(VGG-16/19):deeper layers<br />
Inception/GoogLeNet:filter concatenation(combining many convolution operations and pooling operations)<br />
ResNet:a stack of many residual blocks,deal with vanishing and exploding gradient problems,a deep learning model can be actually deeeeeeeeep<br />
<img alt="" src="../img/image-22.png" />  </p>
<h2 id="lecture-14">Lecture 14<a class="headerlink" href="#lecture-14" title="Permanent link">&para;</a></h2>
<p>Lab(pytorch)  </p>
<h2 id="lecture-15">Lecture 15<a class="headerlink" href="#lecture-15" title="Permanent link">&para;</a></h2>
<h3 id="natural-language-processing">Natural Language Processing<a class="headerlink" href="#natural-language-processing" title="Permanent link">&para;</a></h3>
<p>Varying size input(<code>nn.linear(fixed_size)</code>) and order<br />
sequence modelling:<br />
Language Modelling(LM) is the task of predicting what the word comes next<br />
<span class="arithmatex">\(P(x^{(t+1)}|x^{(t)},...,x^{(1)})\)</span>  </p>
<h4 id="recurrent-neural-networksrnn">Recurrent Neural Networks(RNN)<a class="headerlink" href="#recurrent-neural-networksrnn" title="Permanent link">&para;</a></h4>
<p>递归/循环神经网络<br />
[Problem] The ability of receiving many many tokens are relatively weak(compared to Transformers in Lecture 16)<br />
<img alt="" src="../img/image-23.png" /><br />
<span class="arithmatex">\(A_t=tanh(Ux_t+wA_{t-1})\\h_t=softmax(VA_t)\)</span><br />
softmax:output layer -&gt; probability(for sampling),<span class="arithmatex">\(softmax=\frac{e^{z_i}}{\sum_{j=1}^Ke^{z_j}}\)</span><br />
RNN can process any length input;in theory it can use the info from many steps back;model size doesn't change for longer input;same weights applied on every timestep<br />
RNN cannot work in parallel and in practice,it's difficult to access info many steps back<br />
Backpropagation Through Time(BPTT)<br />
loss:<span class="arithmatex">\(E_t(y_t,\hat{y_t})=-y_t\log \hat{y_t}\)</span><br />
<span class="arithmatex">\(E_{all}(y,\hat{y})=\sum_tE_t(y_t,\hat{y_t})\)</span><br />
<span class="arithmatex">\(\frac{\partial E_{all}}{\partial W}=\sum_t\frac{\partial E_t}{\partial W}\)</span><br />
<span class="arithmatex">\(\frac{dE_3}{dW}=\sum_{k=0}^3\frac{\partial E_3}{\partial \hat{y_3}}\frac{\partial \hat{y_3}}{\partial s_3}\frac{\partial s_3}{\partial s_k}\frac{\partial s_k}{\partial W}\)</span><br />
vanishing gradient at the first layer<br />
solution:a better initialization;ReLU(exploding);LSTM  </p>
<h2 id="lecture-16">Lecture 16<a class="headerlink" href="#lecture-16" title="Permanent link">&para;</a></h2>
<h3 id="lstm">LSTM<a class="headerlink" href="#lstm" title="Permanent link">&para;</a></h3>
<p>LSTM(Long Short-Term Memory):a separate cell memory with gates(forget is allowed)<br />
Gated Recurrent unit<br />
A LSTM unit in composed of a cell state,a hidden state and three control gates(input,output and forget gate).The cell stores long-term info and LSTM can erase,write and read info from cell<br />
<img alt="" src="../img/image-24.png" /><br />
forget gate:<span class="arithmatex">\(f_t=\sigma(W_f\cdot[h_{t-1},x_t]+b_f)\in[0,1]\)</span>  </p>
<ul>
<li>input:previous hidden state <span class="arithmatex">\(h_{t-1}+\)</span>current token <span class="arithmatex">\(x_t\)</span> </li>
<li>output<span class="arithmatex">\(f_t=0\rightarrow\)</span> erase some info  </li>
</ul>
<p>forget gate controls the memory of previous info<br />
input gate:
$$
\begin{aligned}
i_t&amp;=\sigma(W_i\cdot[h_{t-1},x_t]+b_i)\\tilde{C_t}&amp;=tanh(W_C\cdot[h_{t-1},x_t]+b_C)
\end{aligned}
$$<br />
<span class="arithmatex">\(i_t\)</span> controls which part of <span class="arithmatex">\(\tilde{C_t}\)</span> is added to <span class="arithmatex">\(C_t\)</span><br />
input gate controls the inclusion of input token  </p>
<p>Integration:<span class="arithmatex">\(C_t=f_t*C_{t-1}+i_t*\tilde{C_t}\)</span><br />
output gate:<br />
$$
\begin{aligned}
o_t&amp;=\sigma(W_o\cdot[h_{t-1},x_t]+b_o)\
h_t&amp;=o_t*tanh(C_t)
\end{aligned}
$$</p>
<p>output gate forms the new hidden layer <span class="arithmatex">\(h_t\)</span><br />
LSTM architecture makes it easier for RNN to preserve info over many timesteps(e.g.forget gate=1,input gate=0)<br />
LSTM does not guarantee that there's no vanishing/exploding gradient,but it provides an easier way for the model to learn long-distance dependencies  </p>
<h3 id="rnn-types">RNN types<a class="headerlink" href="#rnn-types" title="Permanent link">&para;</a></h3>
<p>one-to-one:MLP(Multi-Layer Perceptron)<br />
one-to-many:article generation<br />
many-to-one:emotion analysis,article classification<br />
many-to-many(input length<span class="arithmatex">\(\neq\)</span>output length):machine translation<br />
many-to-many(input length<span class="arithmatex">\(=\)</span>output length):Name Entity Recognition(NER)人名,书名,地名识别<br />
many-to-many RNN:encoder(input)-decoder(output)  </p>
<h3 id="attention-mechanism">Attention Mechanism<a class="headerlink" href="#attention-mechanism" title="Permanent link">&para;</a></h3>
<p>sequence-to-sequence(seq-to-seq) model:encoder -&gt; context vector -&gt; decoder<br />
[problem] easy to forget the first part when the sequence is long(information bottleneck)<br />
[solution] attention scores:dot product of output token &amp; current read input<br />
<img alt="" src="../img/image-25.png" /><br />
an attention function can be described as mapping a query and a set of key-value pairs to an output<br />
<span class="arithmatex">\(Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt{d_k}})V\)</span><br />
<span class="arithmatex">\(K\)</span>:index,<span class="arithmatex">\(V\)</span>:content,<span class="arithmatex">\(\sqrt{d_k}\)</span>:dividing the dimension to make the variance = 1     </p>
<h3 id="transformer">Transformer<a class="headerlink" href="#transformer" title="Permanent link">&para;</a></h3>
<p>originally used for translation<br />
Transformer is another encoder-decoder model based solely on attention mechanisms that dispense with RNN entirely<br />
self-attention(for understanding)encoding:<span class="arithmatex">\(Attention(V,V,V)\)</span> replaces the recursion(no order,can work in parallel)<br />
position encoding using sine/cosine/ROPE<br />
residual connection between layers(idea from ResNet)<br />
encoder-decoder attention(cross attention):<span class="arithmatex">\(Attention(Q,V,V)\)</span><br />
multi-head attention:each head specializes on different fields<br />
<img alt="" src="../img/image-26.png" />  </p>
<h2 id="lecture-17">Lecture 17<a class="headerlink" href="#lecture-17" title="Permanent link">&para;</a></h2>
<p>Encoder does not exist in today's GPT,QWEN,...<br />
MFU:model flops utilization，GPU算力的利用程度  </p>
<h3 id="bert">BERT<a class="headerlink" href="#bert" title="Permanent link">&para;</a></h3>
<p>BERT(Bidirectional Encoder Representations from Transformers) is a pre-trained language model based on Transformer<br />
MLM(Masked Language Model pretraining task):mask 15\% of the words and predict<br />
BERT can tackle a broad set of NLP tasks(general purpose) by applying a pre-training and fine-tuning(only learn the last layer) approach<br />
BERT proves that transformer can scale.Scaling can achieve AGI.(Artificial General Intelligence)<br />
downstream tasks solved by BERT:<br />
MNLI(Multi-Genre Natural Language Inference):判断前提和假设的逻辑关系<br />
NER(Named Entity Recognition)<br />
SQuAD(Stanford Question Answering Dataset):完型填空<br />
...  </p>
<h3 id="batch-normalization">Batch Normalization<a class="headerlink" href="#batch-normalization" title="Permanent link">&para;</a></h3>
<p>ICML:Test of Time Award(2025.7)<br />
Batch normalization is a special layer that can alleviate exploding gradient and vanishing gradient(by controlling the output range of each layer)<br />
a basic building block of neural networks consists:Conv -&gt; BN -&gt; ReLU<br />
With the help of BN,gradients distribute more concentrated<br />
normalize:<br />
$$
\hat{x}^{(k)}=\frac{x^{(k)}-E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}
$$
The normalization constrain the expressiveness of DNN,but if we amplify <span class="arithmatex">\(w\)</span> with <span class="arithmatex">\(\gamma\)</span>,increase <span class="arithmatex">\(b\)</span> with <span class="arithmatex">\(\beta\)</span>,normalization of <span class="arithmatex">\(y\)</span> stays the same(<span class="arithmatex">\(\gamma,\beta\)</span> is learned by DNN)<br />
$$
\hat{x}^{(k)}=\gamma \times \frac{x^{(k)}-E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}+\beta
$$
How to compute E and Var:sample a batch of images for each iteration,then adopt exponentially decaying to make E and Var stable during training<br />
$$
\hat{E}[x^{(k)}]<em iter="iter">{iter+1}=0.9 \times \hat{E}[x^{(k)}]</em>_i
$$}+0.1\times \frac{1}{m}\sum_{i=1}^mx^{(k)</p>
<h3 id="data-augmentation">Data Augmentation<a class="headerlink" href="#data-augmentation" title="Permanent link">&para;</a></h3>
<p>Data Augmentation is a common way to enlarge dataset and avoid overfitting<br />
common methods:crop(裁剪) and resize,flipping,saturation(饱和度),rotate,luminosity(亮度)<br />
The label does not change  </p>
<h3 id="neural-network-pruning">Neural Network Pruning<a class="headerlink" href="#neural-network-pruning" title="Permanent link">&para;</a></h3>
<p>deploying CNNs on resources-restricted mobile devices is challenging<br />
pruning:delete unimportant components in nerual networks -&gt; less parameters and less computations<br />
universal pipeline:get a (pre)trained model -&gt; prune unimportant components -&gt; fine-tune the model  </p>
<ul>
<li>weight-level pruning:  </li>
<li>set unimportant weights to 0  </li>
<li>cut down parameters directly  </li>
<li>filter-level pruning:  </li>
<li>pruning unimportant filters(feature maps)  </li>
<li>cut down parameters and computations directly  </li>
<li>layer-level pruning:  </li>
<li>pruning redundant layers(blocks)  </li>
<li>cut down parameters and computations directly  </li>
</ul>
<h4 id="weight-level">weight-level<a class="headerlink" href="#weight-level" title="Permanent link">&para;</a></h4>
<p>set (often) small weights to 0 -&gt; sparse matrix -&gt; Huffman coding for easy compression,cuSPARSE for faster computing  </p>
<h4 id="filter-level">filter-level<a class="headerlink" href="#filter-level" title="Permanent link">&para;</a></h4>
<p>filters with small <span class="arithmatex">\(l_p\)</span> norm are unimportant<br />
feature maps with small mean activation values are unimportant<br />
filters expressing similar information(linear corrrelation,cosine similarity) are unimportant  </p>
<h4 id="layer-levelblock-level">layer-level/block-level<a class="headerlink" href="#layer-levelblock-level" title="Permanent link">&para;</a></h4>
<p>prune unimportant blocks<br />
<img alt="" src="../img/image-27.png" />  </p>
<h3 id="generative-adversarial-networksgan">Generative Adversarial Networks(GAN)<a class="headerlink" href="#generative-adversarial-networksgan" title="Permanent link">&para;</a></h3>
<p>Given data <span class="arithmatex">\(\left\{x_i\right\}_{i\in I}\)</span> sampled from real distribution <span class="arithmatex">\(p(x)\)</span><br />
We want to sample new data <span class="arithmatex">\(x\sim p(x)\)</span><br />
building a sampler:understand the underlying distribution of data points:output samples similar but not the same as training data samples,representative of the underlying factors of variation in the training distribution<br />
sample <span class="arithmatex">\(z\)</span> from a fixed noise prior distribution(uniform or Gaussian)<br />
Pass the noise <span class="arithmatex">\(z\)</span> through a generator <span class="arithmatex">\(G\)</span> and output <span class="arithmatex">\(G(z)\)</span><br />
GAN idea:use another network D,called the discriminator to classify the generated data and the real data<br />
<img alt="" src="../img/image-28.png" /><br />
Finally,D is deprecated(the output of any input is 0.5)<br />
In real GAN,the suggestion of D is actually the gradient of the generated sample<br />
D and G converges at a Nash Equilibrium<br />
training process:A minimax game between G and D<br />
objective function of G:
$$
min_Gmax_D\mathbb{E}<em data="data">{x\sim p</em>[\log (1-D(G(z)))]
$$
}}[\log D(x)]+\mathbb{E}_{z\sim p_z<span class="arithmatex">\(D(x)\in[0,1]\)</span>:confidence,<span class="arithmatex">\(p_{data}\)</span>:real data distribution,<span class="arithmatex">\(p_z\)</span>:prior distribution of noise(often Gaussian)<br />
D tries to maximize the log-likelihood for the binary classification(output <span class="arithmatex">\(1\)</span> for real data and output <span class="arithmatex">\(0\)</span> for generated data)<br />
G tries to minimize the log-probability of its samples being classified as "fake" by D<br />
cheat:G gets the gradient from D and uses the opposite of the gradient for training<br />
BigGANs(2019):采样<span class="arithmatex">\(z_1,z_2\)</span>，线性插值，输入空间的线性操作-&gt;语义空间的平滑转化(流形结构)  </p>
<h3 id="diffusion">*Diffusion<a class="headerlink" href="#diffusion" title="Permanent link">&para;</a></h3>
<p>forward:add noise<br />
backward:eliminate the noise<br />
generate images from a complete random noise<br />
stable training process  </p>
<h2 id="lecture-18">Lecture 18<a class="headerlink" href="#lecture-18" title="Permanent link">&para;</a></h2>
<h3 id="adversial-attacks-and-defense">Adversial Attacks and Defense<a class="headerlink" href="#adversial-attacks-and-defense" title="Permanent link">&para;</a></h3>
<p>Adding a small shift onto the input image can completely change the prediction of DNN on purpose<br />
<span class="arithmatex">\(x + v = x'\)</span><br />
<span class="arithmatex">\(x'\)</span>:adversial samples  </p>
<h4 id="attack">attack<a class="headerlink" href="#attack" title="Permanent link">&para;</a></h4>
<p>[Target] finding <span class="arithmatex">\(v\)</span><br />
find <span class="arithmatex">\(v=\Delta x\)</span> that makes the prediction wrong,<span class="arithmatex">\(\iff v=\Delta x\)</span> increases the loss <span class="arithmatex">\(l\)</span><br />
attack algorithm:<br />
training process:<span class="arithmatex">\(\Delta\theta=-lr\times\frac{\partial l}{\partial \theta},lr:learning\ rate\)</span><br />
<span class="arithmatex">\(v=\Delta x=\epsilon\times\frac{\partial l}{\partial x},x:input\)</span><br />
Threat model:visible parameters <span class="arithmatex">\(\theta\)</span><br />
However,the attacking <span class="arithmatex">\(x'\)</span> computed on network A can be transferred to B even if we don't know the parameters of B<br />
White-Box attack:full access to the entire model<br />
Black-Box attack:no access to target model B,only have access to model A  </p>
<h4 id="defense">defense<a class="headerlink" href="#defense" title="Permanent link">&para;</a></h4>
<p>correctly classify <span class="arithmatex">\(x'\rightarrow\)</span> train with <span class="arithmatex">\(x'\)</span><br />
Adversial training<br />
Repeat:<br />
1. in each iteration of training,we first attack the model to get <span class="arithmatex">\(x'\)</span><br />
$$
x'=x+\epsilon\times\frac{\partial l}{\partial x}
$$
2. compute loss value given <span class="arithmatex">\(x'\)</span>:<br />
$$
L'=CrossEntropy(\theta,x',y)
$$
3. minimize <span class="arithmatex">\(L'\)</span><br />
$$
\Delta\theta=-lr\times\frac{\partial L'}{\partial\theta}
$$</p>
<h3 id="neural-network-architecture-searchnas">Neural Network Architecture Search(NAS)<a class="headerlink" href="#neural-network-architecture-searchnas" title="Permanent link">&para;</a></h3>
<p>For manually designed blocks,they are often empirical or even random choices,but the question is,are they good enough?<br />
NAS:a NN = a directed acyclic graph(densely connected),edges represents operations like ReLU,conv;nodes represents input and output,and we want to determine the best operation between each two nodes<br />
candidate operations:3x3 conv,5x5 conv,pooling,etc.<br />
<img alt="" src="../img/image-29.png" />  </p>
<h3 id="combining-modelsensemble-methods">Combining Models(Ensemble Methods)<a class="headerlink" href="#combining-modelsensemble-methods" title="Permanent link">&para;</a></h3>
<h4 id="baggingbootstrap-aggregating">Bagging(Bootstrap Aggregating)<a class="headerlink" href="#baggingbootstrap-aggregating" title="Permanent link">&para;</a></h4>
<p>1.re-sample N samples from dataset D uniformly with replacement(放回采样)<br />
2.aggregating:voting for classification/average for regression<br />
large performance when the base learner is unstable(large variance)<br />
The base learner should be aware of the small shifts,overfitting is allowed<br />
Bagging effectively reduces the higher-order components while not affecting the linear components.Bagging is better applied with highly nonlinear learners.<br />
<strong>Decision Tree</strong> is a good choice:non-linear,easy to use and easy to overfit  </p>
<h4 id="random-forest">Random Forest<a class="headerlink" href="#random-forest" title="Permanent link">&para;</a></h4>
<p>use decision tree as a basic unit in bagging<br />
1. Bootstrap sampling:random sampling with replacement<br />
2. create T new training sets<br />
3. get T models  </p>
<p>increase the variation of each tree:double randomization<br />
1.random sampling<br />
2.randomized feature selection(subset <span class="arithmatex">\(f\)</span> out of <span class="arithmatex">\(F\)</span>) at each split step<br />
Construction:no pruning,stop until validation error never decrease<br />
parallel ensemble</p>
<h4 id="boosting">Boosting<a class="headerlink" href="#boosting" title="Permanent link">&para;</a></h4>
<p>sequential ensemble method:modify the weight of different training samples and generate a model on the modified training set<br />
boosting process:increase the weight of misclassified samples per step  </p>
<h5 id="adaboost">AdaBoost<a class="headerlink" href="#adaboost" title="Permanent link">&para;</a></h5>
<ol>
<li>Initialize the weight coefficient <span class="arithmatex">\(w\)</span> by setting <span class="arithmatex">\(w_n^{(i)}=1/N\)</span>  </li>
<li>For <span class="arithmatex">\(m=1,...,M\)</span>:
(a) Fit a classifier <span class="arithmatex">\(y^{(m)}(x)\)</span> to the training data by minimizing the weighted error function<br />
$$
J_m=\sum_{n=1}^Nw_n^{(m)}I(y^{(m)}(x_n)\neq t_n)
$$
(b) Evaluate the Error-rate:<br />
$$
\epsilon_m=\frac{\sum_{n=1}^Nw_n^{(m)}I(y^{(m)}(x_n)\neq t_n)}{\sum_{n=1}^Nw_n^{(m)}}
$$
$$
\alpha_m=\ln\frac{1-\epsilon_m}{\epsilon_m}
$$
<span class="arithmatex">\(\alpha_m\)</span>:log odds,smaller the error rate,bigger the value<br />
(c) Update weight coefficients:(<span class="arithmatex">\(t_n\in\left\{1,-1\right\}\)</span>)<br />
$$
\begin{aligned}
w_n^{m+1}&amp;=w_n^{(m)}\exp\left{\alpha_mI(y^{(m)}(x_n)\neq t_n)\right}=\begin{cases}w_n^{(m)}\frac{1-\epsilon_m}{\epsilon_m},if y^{(m)} makes error\w_n^{(m)},otherwise\end{cases}\
w_n^{m+1}&amp;=w_n^{(m)}\exp\left{-\frac{1}{2}\alpha_mt_ny^{(m)}(x_n)\right}
\end{aligned}
$$</li>
<li>Make predictions using the final model<br />
$$
Y_M(x)=sign(\sum_{m=1}^M\alpha_my^{(m)}(x))
$$
weight coefficient <span class="arithmatex">\(\alpha_m\)</span> gives weight to more accurate classifiers  </li>
</ol>
<p>[Insights] In each round,the algorithm tries to get a <strong>different base learner</strong><br />
If <span class="arithmatex">\(g_m=minJ_m\)</span> is not good for <span class="arithmatex">\(w^{(m+1)}\Rightarrow g_{m+1}=minJ_{m+1}\)</span> diverse from <span class="arithmatex">\(g_m\)</span><br />
[Idea] construct <span class="arithmatex">\(w^{(m+1)}\)</span> to make <span class="arithmatex">\(g_m\)</span> random-like:<br />
<span class="arithmatex">\(\frac{\sum_{n=1}^Nw_n^{(m+1)}I(y_n^{(m)})\neq t_n}{\sum_{n=1}^Nw_n^{(m+1)}}=\frac 1 2\Rightarrow w_n^{(m+1)}=w_n^{(m)}\frac{1-\epsilon_m}{\epsilon_m},if\ wrong\)</span><br />
[Insights] Adaboost can be seen as a sequential optimization process of an additive model under exponential error  </p>
<h4 id="gradient-boosting-decision-treegbdt">Gradient Boosting Decision Tree(GBDT)<a class="headerlink" href="#gradient-boosting-decision-treegbdt" title="Permanent link">&para;</a></h4>
<p>CART(regression tree):<span class="arithmatex">\((j,s)\)</span> pair for region splitting<br />
GBDT:each time predict the remaining data and summation all the models<br />
Initialize:<span class="arithmatex">\(f_0(x)=0\)</span><br />
For <span class="arithmatex">\(m=1,2,...,M\)</span>
  - Compute the residual:<span class="arithmatex">\(r_{mi}=y_i-f_{m-1}(x_i)\)</span><br />
  - Treat <span class="arithmatex">\(r_{mi}\)</span> as <span class="arithmatex">\(y_i\)</span> and learn a regression tree <span class="arithmatex">\(h_m(x)\)</span><br />
  - Update <span class="arithmatex">\(f_m(x)=f_{m-1}(x)+h_m(x)\)</span>  </p>
<p>Final model:<span class="arithmatex">\(f_M(x)=\sum_{m=1}^Mh_m(x)\)</span>  </p>
<p>*useful extensions:XGBoost,LightGBM  </p>
<h2 id="lecture-19">Lecture 19<a class="headerlink" href="#lecture-19" title="Permanent link">&para;</a></h2>
<h3 id="k-nearest-neighbor-classifierknn">K-Nearest Neighbor Classifier(KNN)<a class="headerlink" href="#k-nearest-neighbor-classifierknn" title="Permanent link">&para;</a></h3>
<p>require three things:<br />
- stored records<br />
- Distance Metric<br />
- The value of k  </p>
<p>classify:<br />
- compute distance<br />
- identify k nearest neighbor
- majority voting  </p>
<p>no parameters in KNN(k is not learnt,k is a hyperparameter):lazy-classifier/no training<br />
Effective number of parameters:N/k  </p>
<p>*distance that is difficult to compute:social network -&gt; K-medoids中心点算法  </p>
<h3 id="metric-learning">Metric Learning<a class="headerlink" href="#metric-learning" title="Permanent link">&para;</a></h3>
<p>object comparison:not all features are equally important<br />
[Definition] learn a metric M that better distinguishes different classes given the real data<br />
$$
\rho_M(x,y)=\sqrt{(x-y)^TM(x-y)}
$$
new inner product<br />
Optimization problem:similar set S,dissimilar set D<br />
$$
large \rho for D \
small \rho for S 
$$
minimize loss function:<br />
$$
L(M)=\sum_{(x,x')\in S}\rho_M^2(x,x')-\lambda\sum_{(x,x')\in D}\rho_M^2(x,x')
$$</p>
<h4 id="mmcmahalanobis-metric-for-clustering">MMC(Mahalanobis Metric for Clustering)<a class="headerlink" href="#mmcmahalanobis-metric-for-clustering" title="Permanent link">&para;</a></h4>
<p>Find the best metric M for clustering based on optimization<br />
$$
min_{M\in\mathbb{R}^{d\times d}}\sum_{(x_i,x_j)\in S}\rho_M^2(x_i,x_j),s.t.\sum_{(x_i,x_j)\in D}\rho_M(x_i,x_j)\ge 1,M\succeq 0
$$
(1) Why positive semi-definite of M?<br />
<span class="arithmatex">\(\rho_M(x,y)\)</span> non-negative<br />
(2) Why <span class="arithmatex">\(\sum_{(x_i,x_j)\in D}\rho_M(x_i,x_j)\ge 1\)</span> instead of <span class="arithmatex">\(\rho_M^2(x_i,x_j)\)</span><br />
Rayleigh-quotient will reduce the problem to single dimension(Derivation is omitted)<br />
Application:无监督表征学习，对比学习  </p>
<h3 id="aknn-search">AKNN Search<a class="headerlink" href="#aknn-search" title="Permanent link">&para;</a></h3>
<p>high-dimensional sample:<span class="arithmatex">\(O(N)\)</span> for each test data(Brute-force search)<br />
Text-search:inverted-file index<br />
Image:SIFT,HoG,GIST<br />
CNN<br />
CLIP:对比学习pre-training<br />
Given a dataset D consists of n d-dim data points<br />
finding the nearest neighbor of a query:<span class="arithmatex">\(O(nd+n)\)</span><br />
finding the k nearest neighbor:<span class="arithmatex">\(O(nd+klogn)\)</span><br />
<span class="arithmatex">\(\epsilon\)</span>-approximate nearest neighbor(ANN) search  </p>
<h4 id="kd-tree">KD-tree<a class="headerlink" href="#kd-tree" title="Permanent link">&para;</a></h4>
<p>Spatial partition and recursive hyperplane decomposition<br />
<img alt="" src="../img/image-30.png" /><br />
Worst:<span class="arithmatex">\(O(n)\)</span>,Best:<span class="arithmatex">\(O(logn)\)</span><br />
*flann<br />
Locality Sensitive Hashing(LSH)<br />
$$
h(x)=sgn(w^Tx-b)
$$
Quantization based(FAISS in Facebook)<br />
Graph based:neighbor's neighbor is likely the neighbor<br />
weighted KNN<br />
density distance:Gaussian kernel <span class="arithmatex">\(d=exp((x_1-x_2)^2/\sigma^2)\)</span>  </p>
<h2 id="lecture-20">Lecture 20<a class="headerlink" href="#lecture-20" title="Permanent link">&para;</a></h2>
<h3 id="quiz_1">quiz<a class="headerlink" href="#quiz_1" title="Permanent link">&para;</a></h3>
<p><img alt="" src="../img/image-31.png" /><br />
Lab(Transformer)  </p>
<h2 id="lecture-21">Lecture 21<a class="headerlink" href="#lecture-21" title="Permanent link">&para;</a></h2>
<h3 id="reinforcement-learning">Reinforcement Learning<a class="headerlink" href="#reinforcement-learning" title="Permanent link">&para;</a></h3>
<p>AlphaGo(2016)by Google Deepmind,GPT-o1(2024)by Openai<br />
agent-environment interaction:action:<span class="arithmatex">\(A_t\)</span>,reward:<span class="arithmatex">\(R_t\)</span>,state:<span class="arithmatex">\(S_t\)</span><br />
agent:learner and decision-maker<br />
environment:interact with<br />
reward:special numerical values the agent try to maximize<br />
state:any useful information for making action<br />
action:can be discrete(Go) or continuous(VLA,Vision-Language-Action model),a <span class="arithmatex">\(softmax\)</span> is needed<br />
training data:State-Action-Reward:(S,A,R)<br />
problem:number of training samples,it may be too hard to get a reward R<br />
[goal] optimal policy for maximizing long-term reward<br />
[feature] multistage decisionmaking process(Markovian);learn by trial-and-error;delayed effect<br />
elements:policy <span class="arithmatex">\(\pi(s)\)</span>(map from state to action,may be stochastic);reward function;value function <span class="arithmatex">\(v_{\pi}(s)\)</span>(total expected reward for a state or state-action pair)<br />
model:prediction of the environment(state change)(model-free and model-based)<br />
[Solution] value iteration and policy iteration(dynamic programming);Q-learning  </p>
<h4 id="markov-decision-processmdp">Markov Decision Process(MDP)<a class="headerlink" href="#markov-decision-processmdp" title="Permanent link">&para;</a></h4>
<p>policy:<span class="arithmatex">\(\pi(a|s)\)</span>:the probability that <span class="arithmatex">\(A_t=a,if\ S_t=s\)</span><br />
reward hypothesis:the goal is to maximization of the expected value of the cumulative sum of reward(optimal policy corresponds to the max reward)<br />
returns:<span class="arithmatex">\(G_t\)</span>:cumulative sum of reward<br />
episodic task:after some special states the interaction should stop,<span class="arithmatex">\(G_t=R_{t+1}+R_{t+2}+...+R_T,T\)</span> is the time of the final state<br />
continuous task:<span class="arithmatex">\(G_t=\sum_{k=0}^{\infty}\gamma^kR_{t+k+1},0\le\gamma&lt;1,\gamma:\)</span>discount rate<br />
[Property] Markov(finite):interaction history <span class="arithmatex">\(\left\{S_0,A_0,R_1,...,S_{t-1},A_{t-1},R_t,S_t,A_t\right\}\)</span><br />
the probability of next state is <span class="arithmatex">\(s'\)</span> and next reward <span class="arithmatex">\(r\)</span>:<br />
$$
Pr\left{S_{t+1}=s',R_{t+1}=r|S_0,A_0,R_1,...,S_{t-1},A_{t-1},R_t,S_t,A_t\right}
$$
The state has the Markov property if <span class="arithmatex">\(\forall history,s',r\)</span>,we have:<br />
$$
\begin{aligned}
&amp;Pr\left{S_{t+1}=s',R_{t+1}=r|S_0,A_0,R_1,...,S_{t-1},A_{t-1},R_t,S_t,A_t\right}=\
&amp;Pr\left{S_{t+1}=s',R_{t+1}=r|S_t,A_t\right}
\end{aligned}
$$
dynamics:<span class="arithmatex">\(p(s',r|s,a)=Pr\left\{S_{t+1}=s',R_{t+1}=r|S_t,A_t\right\}\)</span><br />
expected reward for state-action pairs:<br />
$$
r(s,a)=\mathbb{E}[R_{t+1}|S_t=s,A_t=a]=\sum_rr\sum_{s'}p(s',r|s,a)
$$
state-transition probabilities:<br />
$$
p(s'|s,a)=Pr\left{S_{t+1}=s',R_{t+1}=r|S_t,A_t\right}=\sum_rp(s',r|s,a)
$$
state value function for policy <span class="arithmatex">\(\pi\)</span>:<br />
$$
v_{\pi}(s)=\mathbb{E}<em _pi="\pi">{\pi}[G_t|S_t=s]=\mathbb{E}</em>|S_t=s]
$$
action(state-action) value function for policy }[\sum_{k=1}^{\infty}\gamma^kR_{t+k+1<span class="arithmatex">\(\pi\)</span>:<br />
$$
\begin{aligned}
q_{\pi}(s,a)&amp;=\mathbb{E}<em _pi="\pi">{\pi}[G_t|S_t=s,A_t=a]\
&amp;=\mathbb{E}</em>|S_t=s,A_t=a]
\end{aligned}
$$}[\sum_{k=1}^{\infty}\gamma^kR_{t+k+1</p>
<h2 id="lecture-22">Lecture 22<a class="headerlink" href="#lecture-22" title="Permanent link">&para;</a></h2>
<ol>
<li>massive rollouts for data collection  </li>
<li>estimate <span class="arithmatex">\(v\)</span> and <span class="arithmatex">\(q\)</span> using the neural network  </li>
<li>map them to the policy <span class="arithmatex">\(\pi\)</span>  </li>
</ol>
<p>Bellman equation(relationship of <span class="arithmatex">\(v\)</span> and <span class="arithmatex">\(q\)</span>): <br />
$$
\begin{aligned}
v_{\pi}(s)&amp;=\mathbb{E}<em _pi="\pi">{\pi}[q</em>(s,a)\
q_{\pi}(s,a)&amp;=\mathbb{E}}(s,A_t)|S_t=s]=\sum_a\pi(a|s)q_{\pi<em t_1="t+1">{\pi}[R</em>)|S_t=s,A_t=a]\
&amp;=\sum_{s',r}p(s',r|s,a)(r+\gamma v_{\pi}(s'))\
v_{\pi}(s)&amp;=\sum_a(\pi(a|s)\sum_{s',r}p(s',r|s,a)(r+\gamma v_{\pi}(s')))
\end{aligned}
$$
optimal value/action function:optimal policy(}+\gamma v_{\pi}(S_{t+1<span class="arithmatex">\(\pi_*\)</span> always exists)<br />
查S-A表(dynamic programming)<br />
e.g.The Grid World<br />
<img alt="" src="../img/image-32.png" /><br />
<span class="arithmatex">\(P=0.8\)</span> in the direction you want to go,<span class="arithmatex">\(P=0.2\)</span> in perpendicular(<span class="arithmatex">\(0.1\)</span> left,<span class="arithmatex">\(0.1\)</span> right),<span class="arithmatex">\(-0.04\)</span> each step,<span class="arithmatex">\(\gamma=1\)</span>(default)<br />
start from <span class="arithmatex">\((1,3)\)</span>:<br />
$$
\begin{aligned}
v_{\pi}(s)&amp;=\sum_a\pi(a|s)\sum_{s',r}p(s',r|s,a)(r+\gamma v_{\pi}(s'))\
&amp;=0.8<em>1</em>(-0.04+1<em>0.868)+0.1</em>1<em>(-0.04+1</em>0.812)+0.1<em>1</em>(-0.04+1*0.868)
\end{aligned}
$$</p>
<h3 id="dynamic-programming">Dynamic Programming<a class="headerlink" href="#dynamic-programming" title="Permanent link">&para;</a></h3>
<p>[Assumption] finite MDP,existing probabilities <span class="arithmatex">\(p(s',r|s,a)\)</span><br />
<img alt="" src="../img/image-33.png" /><br />
<span class="arithmatex">\(v(s_t)=\mathbb{E}_{\pi}[R_{t+1}+\gamma v(s_{t+1})]\)</span><br />
policy evaluation:iterative policy evaluation<br />
$$
v_{k+1}(s)=\sum_a(\pi(a|s)\sum_{s',r}p(s',r|s,a)(r+\gamma v_k(s')))
$$
Get the sequence of <span class="arithmatex">\(\left\{v_k(s)\right\}\)</span> using the Bellman equation until it converges to <span class="arithmatex">\(\left\{v_{\pi}(s)\right\}\)</span>(it must converge if <span class="arithmatex">\(k\)</span> sufficiently large)<br />
policy improvement:For any pair of deterministic policies,<span class="arithmatex">\(q_{\pi}(s,\pi'(s))\ge v_{\pi}(s)\iff v_{\pi'}(s)&gt;v_{\pi}(s)\)</span><br />
<span class="arithmatex">\(\pi'(s)=argmax_a\sum_{s',r}p(s',r|s,a)[r+\gamma v_{\pi}(s')]\)</span>:greedy method<br />
Policy Iteration:<br />
(1) random initialization<br />
loop:<br />
(2) policy evaluation<br />
(3) policy improvement  </p>
<p><img alt="" src="../img/image-34.png" /><br />
Value iteration(find the optimal <span class="arithmatex">\(v_*(s)\)</span> directly)<br />
$$
v_{k+1}(s)=max_a\sum_{s',r}p(s',r|s,a)(r+\gamma v_k(s'))
$$</p>
<h3 id="monte-carlo-method">Monte Carlo Method<a class="headerlink" href="#monte-carlo-method" title="Permanent link">&para;</a></h3>
<p>[Problem] the dynamics of the environment <span class="arithmatex">\(p(s',r|s,a)\)</span> is unclear<br />
[Solution] treat the unknown as expectation and estimate by sampling and averaging,<span class="arithmatex">\(q_{\pi}(s,a)=\mathbb{E}[G_t]\)</span>,update value function by sampling return:<br />
$$
v(s_t)\leftarrow v(s_t)+\alpha(G_t-v(s_t))
$$
sufficient exploration is needed<br />
<strong>exploring starts</strong>:first state-action pair sampled from a distribution that every state-action has a non-zero probability<br />
evaluation:Monte Carlo for stable Q,then policy improvement and Monte Carlo estimation for new policy and so on ...<br />
how to treat return list <span class="arithmatex">\(Returns(s,a)\)</span> after policy improvement?<br />
constant-<span class="arithmatex">\(\alpha\)</span> MC:<br />
$$
Q(S_i,A_i)\leftarrow Q(S_i,A_i)+\alpha[G-Q(S_i,A_i)]
$$
<span class="arithmatex">\(\alpha\)</span> is a small constant number(often 0.1)  </p>
<h2 id="lecture-23">Lecture 23<a class="headerlink" href="#lecture-23" title="Permanent link">&para;</a></h2>
<h3 id="temporal-difference-learning">Temporal-Difference Learning<a class="headerlink" href="#temporal-difference-learning" title="Permanent link">&para;</a></h3>
<p>update the value function in only one step(no need to get return)<br />
$$
v(s_t)\leftarrow v(s_t)+\alpha[R_{t+1}+\gamma v(s_{t+1})-v(s_t)]
$$
biased,but converge much faster,sensitive to initial value<br />
TD error:<span class="arithmatex">\(\delta_t=R_{t+1}+\gamma v(s_{t+1})-v(s_t)\)</span><br />
Monte Carlo error can be written as a sum of TD errors<br />
TD is an online fashion:policy evaluation and improvement can be implemented together(evaluation one step then improvement then evaluation one step then improvement...) because it need not to wait until the end of an episode<br />
TD also better compatible with continuing tasks<br />
TD control methods:Sarsa and Q-learning  </p>
<h3 id="sarsa">Sarsa<a class="headerlink" href="#sarsa" title="Permanent link">&para;</a></h3>
<p><span class="arithmatex">\(\epsilon\)</span>-greedy policy:<span class="arithmatex">\(1-\epsilon\)</span> probability to <span class="arithmatex">\(\pi(s)\)</span>,<span class="arithmatex">\(\epsilon\)</span> probability to all actions<br />
$$
Q(S_t,A_t)\leftarrow Q(S_t,A_t)+\alpha[R_{t+1}+\gamma Q(S_{t+1},A_{t+1})-Q(S_t,A_t)]
$$
on-policy:<span class="arithmatex">\(\epsilon\)</span>-greedy for evaluation and improvement  </p>
<h3 id="q-learning">Q-Learning<a class="headerlink" href="#q-learning" title="Permanent link">&para;</a></h3>
<p>Ensure sufficient exploration without harming the optimality(错误的探索会被记住)<br />
off-policy:use another stochastic policy for training data generation<br />
exploitation is always fully-greedy:<span class="arithmatex">\(\pi(s)=argmax_a Q(s,a)\)</span><br />
$$
Q(S_t,A_t)\leftarrow Q(S_t,A_t)+\alpha[R_{t+1}+\gamma max_{a'}Q(S_{t+1},A_{t+1})-Q(S_t,A_t)]
$$
exploration vs exploitation:tradeoff<br />
note:DP is model-based,MC and TD are model-free  </p>
<h3 id="deep-q-learning">Deep Q-Learning<a class="headerlink" href="#deep-q-learning" title="Permanent link">&para;</a></h3>
<p>Beyond finite MDP
$$
Q(S_t,A_t)\leftarrow Q(S_t,A_t)+\alpha[U_t-Q(S_t,A_t)]
$$
<span class="arithmatex">\(U_t\)</span> is an approximation of <span class="arithmatex">\(q_{\pi}(S_t,A_t)\)</span><br />
$$
min_{\theta}\frac 1 2[U_t-\hat{q}(S_t,A_t,\theta)]^2
$$
Then use a NN,this is deep Q-Learning<br />
Experience replay:a memory pool of tuple <span class="arithmatex">\((s_t,a_t,r_t,s_{t+1})\)</span> for the agent<br />
The batch size of SGD is only one(灾难性遗忘)  </p>
<h3 id="double-q-learning">Double Q-Learning<a class="headerlink" href="#double-q-learning" title="Permanent link">&para;</a></h3>
<h2 id="lecture-24">Lecture 24<a class="headerlink" href="#lecture-24" title="Permanent link">&para;</a></h2>
<h3 id="policy-gradient-methods">Policy Gradient Methods<a class="headerlink" href="#policy-gradient-methods" title="Permanent link">&para;</a></h3>
<p>The previous methods are frequently applied to gaming<br />
In real world,state information is not enough,Markov property does not hold<br />
The optimal policy may not be deterministic<br />
e.g. short corridor with switched actions<br />
If the agent can only choose to always move left or right,the reward is <span class="arithmatex">\(-\infty\)</span><br />
$$
\pi(a|s,\theta)=Pr\left{A_t=a|S_t=s,\theta\right}
$$
use state-action function <span class="arithmatex">\(q\)</span> as the objective function<br />
use gradient ascend <span class="arithmatex">\(\nabla_{\theta}\)</span> to optimize policy<br />
$$
\nabla v_{\pi}(s)=\sum_{k=0}^{\infty}\gamma^k\mathbb{E}[G_{t+k}\nabla\log\pi(A_{t+k}|S_{t+k})|S_t=s]
$$
REINFORCE(algorithm): <br />
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">initialize</span> 
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="n">repeat</span> <span class="n">forever</span><span class="p">:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>  <span class="n">generate</span> <span class="n">an</span> <span class="n">episode</span> <span class="n">S_0</span><span class="p">,</span><span class="n">A_0</span><span class="p">,</span><span class="n">R_1</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="n">A_</span><span class="p">{</span><span class="n">T</span><span class="o">-</span><span class="mi">1</span><span class="p">},</span><span class="n">R_T</span><span class="p">,</span><span class="n">S_T</span> <span class="n">using</span> \<span class="n">pi</span><span class="p">(</span><span class="n">a</span><span class="o">|</span><span class="n">s</span><span class="p">,</span>\<span class="n">theta</span><span class="p">)</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>  <span class="nb">set</span> <span class="n">gradient</span> <span class="n">g</span><span class="o">=</span><span class="mi">0</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>  <span class="k">for</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="n">T</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">G_k</span> <span class="o">=</span> <span class="n">R_</span><span class="p">{</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">}</span> <span class="o">+</span> \<span class="n">gamma</span> <span class="n">R_</span><span class="p">{</span><span class="n">k</span><span class="o">+</span><span class="mi">2</span><span class="p">}</span> <span class="o">+</span> <span class="o">...</span> <span class="o">+</span> \<span class="n">gamma</span><span class="o">^</span><span class="p">{</span><span class="n">T</span><span class="o">-</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">}</span> <span class="n">R_T</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">g</span> <span class="o">=</span> <span class="n">g</span> <span class="o">+</span> \<span class="n">gamma</span><span class="o">^</span><span class="n">kG_k</span>\<span class="n">nabla_</span><span class="p">{</span>\<span class="n">theta</span><span class="p">}</span>\<span class="n">log</span>\<span class="n">pi</span><span class="p">(</span><span class="n">A_k</span><span class="o">|</span><span class="n">S_k</span><span class="p">)</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>  \<span class="n">theta</span> <span class="o">=</span> \<span class="n">theta</span> <span class="o">+</span> \<span class="n">alpha</span> <span class="o">*</span><span class="n">g</span>
</code></pre></div>
REINFORCE with baseline:<br />
baseline function:<span class="arithmatex">\(b(s)\)</span>,a human perceived weight for each state gradient<br />
Actor-Critic methods:<br />
estimate policy gradient in TD style,use <span class="arithmatex">\(R_{t+k}+\gamma\hat{v}(S_{t+k+1},w)\)</span> to estimate <span class="arithmatex">\(q\)</span>,use <span class="arithmatex">\(\hat{v}(S_{t+k},w)\)</span> as baseline  </p>
<h3 id="dimensionality-reduction">Dimensionality Reduction<a class="headerlink" href="#dimensionality-reduction" title="Permanent link">&para;</a></h3>
<p>feature engineering:a mapping from input <span class="arithmatex">\(x\)</span> to feature space <span class="arithmatex">\(z\)</span>,where <span class="arithmatex">\(dim(z)&lt;dim(x)\)</span><br />
<span class="arithmatex">\(F(x)=\left\{f_1(x),...,f_d(x)\right\}=z\)</span><br />
If <span class="arithmatex">\(f\)</span> is linear,<span class="arithmatex">\(A^Tx=z\)</span><br />
if <span class="arithmatex">\(f\)</span> is nonlinear,embedding function<br />
feature selection:best subset<br />
<span class="arithmatex">\(A^Tx=z,where\ A\in[0,1]^{p\times d}\)</span>
feature extraction:given <span class="arithmatex">\(x\)</span>,extract <span class="arithmatex">\(z\)</span><br />
unsupervised:PCA<br />
supervised:LDA<br />
semi-supervised:SDA<br />
non-linear:kernel method;manifold learning  </p>
<h4 id="pca">PCA<a class="headerlink" href="#pca" title="Permanent link">&para;</a></h4>
<p>Principal Component Analysis(unsupervised)<br />
The new variables(principal component,PC) are uncorrelated<br />
[Definition] the first PC is <span class="arithmatex">\(z_i^{(1)}=a_1^Tx_i,s.t.max\ var(z^{(1)})\)</span><br />
<span class="arithmatex">\(var(z^{(1)})=a_1^TSa_1,S=\frac 1 n \sum_{i=1}^n (x_i-\overline{x})(x_i-\overline{x})^T,S\)</span> is the covariance matrix<br />
<span class="arithmatex">\(max_{a_1} a_1^TSa_1,s.t.a_1^Ta_1=1\)</span><br />
<span class="arithmatex">\(L=a_1^TSa_1-\lambda(a_1^Ta_1-1)\)</span><br />
<span class="arithmatex">\(\frac{\partial L}{\partial a_1}=0\Rightarrow Sa_1=\lambda a_1\)</span><br />
<span class="arithmatex">\(a_1\)</span> is the eigenvector of S corresponding to the largest eigenvalue <span class="arithmatex">\(\lambda=\lambda_1\)</span><br />
The second PC:<span class="arithmatex">\(max_{a_2}a_2^TSa_2,s.t.a_2^Ta_2=1,cov(z^{(2)},z^{(1)})=0\Rightarrow \lambda_2\)</span><br />
The kth PC is the kth largest eigenvalue of S:<span class="arithmatex">\(\lambda^{(k)}\)</span><br />
1. form the covariance matrix S
2. compute eigenvectors <span class="arithmatex">\(\left\{a_i\right\}_{i=1}^p\)</span><br />
3. use the first <span class="arithmatex">\(d\)</span> eigenvectors to form PCs<br />
4. <span class="arithmatex">\(A=[a_1,...,a_d]\)</span>  </p>
<h2 id="lecture-25">Lecture 25<a class="headerlink" href="#lecture-25" title="Permanent link">&para;</a></h2>
<p>preprocess(normalization):<span class="arithmatex">\(x'=\frac{x-\overline{x}}{\sigma}\)</span><br />
optimality property:<span class="arithmatex">\(min_A \|X-AA^TX\|_F^2,s.t.A^TA=I_d,\|X-\hat{X}\|_F^2\)</span>  </p>
<h3 id="linear-discriminant-analysislda">Linear Discriminant Analysis(LDA)<a class="headerlink" href="#linear-discriminant-analysislda" title="Permanent link">&para;</a></h3>
<p>two classes:Rayleigh quotient,<span class="arithmatex">\(S_W\)</span>:类内散度矩阵，<span class="arithmatex">\(S_B\)</span>:类间散度矩阵<br />
$$
J(a)=\frac{a^TS_Ba}{a^TS_Wa}\iff S_W^{-1}S_B
$$
max eigenvalue of <span class="arithmatex">\(S_W^{-1}S_B\)</span> 
1. form the scatter matrices <span class="arithmatex">\(S_B\)</span> and <span class="arithmatex">\(S_W\)</span><br />
2. compute eigenvectors corresponding to non-zero eigenvalues of <span class="arithmatex">\(S_Ba=\lambda S_Wa\)</span> or <span class="arithmatex">\(S_Ba=\lambda S_Ta\)</span> <br />
3. the transformation <span class="arithmatex">\(A=[a_1,...,a_{c-1}]\)</span>  </p>
<div class="admonition note">
<p class="admonition-title">无论是PCA还是LDA，投影都必须与去中心化后的样本做内积</p>
</div>
<p>*Locality Preserving Projections(LPP)<br />
Regularization on LDA &amp; LPP  </p>
<h3 id="manifold-learning">Manifold Learning<a class="headerlink" href="#manifold-learning" title="Permanent link">&para;</a></h3>
<p>[Definition] Manifold:topological space that locally resembles Euclidean space near each point<br />
Each point has a neighborhood that is homeomorphic(同胚) to the Euclidean space<br />
Multi-Dimensional Scaling(MDS):keep the data distance in the dimension-reduced space<br />
<span class="arithmatex">\(Z=[z_1,z_2,...,z_n],B=Z^TZ\)</span><br />
Given <span class="arithmatex">\(B\)</span>,one possible <span class="arithmatex">\(Z\)</span> can be obtained through eigen-decomposition of <span class="arithmatex">\(B\)</span>  </p>
<ol>
<li>Input:Distance Matrix <span class="arithmatex">\(D\)</span>  </li>
<li>Algorithm:
(1) compute <span class="arithmatex">\(d_{i:}^2,d_{:j}^2,d_{::}^2\)</span><br />
(2) compute inner product B
(3) eigen-decomposition on B
(4) select k biggest eigenvalues and obtain <span class="arithmatex">\(\Lambda^{\frac 1 2}_*U^T_*\)</span>  </li>
<li>Output:k-dim data matrix Z  </li>
</ol>
<h4 id="isomap">ISOMAP<a class="headerlink" href="#isomap" title="Permanent link">&para;</a></h4>
<p>KNN graph -&gt; distance between two points:shortest path distance on the graph<br />
1. define graph G,connect neighbor(closer <span class="arithmatex">\(\epsilon\)</span> or k nearest) points and define dege length = Euclidean distance<br />
2. compute shortest paths <span class="arithmatex">\(d(x_i,x_j)\)</span> on G<br />
3. Apply MDS on <span class="arithmatex">\(d\)</span> to find lower-dim embedding  </p>
<h4 id="locally-linear-embeddinglle">Locally Linear Embedding(LLE)<a class="headerlink" href="#locally-linear-embeddinglle" title="Permanent link">&para;</a></h4>
<p>reconstruct neighbor with linear weights<br />
<span class="arithmatex">\(J(W)=\sum_{i=1}^n\|x_i-\sum_jw_{ij}x_j\|^2,s.t.\sum_jw_{ij}=1\)</span>  </p>
<h4 id="robust-pca">Robust PCA<a class="headerlink" href="#robust-pca" title="Permanent link">&para;</a></h4>
<p>PCA:<span class="arithmatex">\(min\|X-L_0\|^2,subject\ to\ rank(L_0)\le k\)</span><br />
<span class="arithmatex">\(X=L_0 + S_0,S_0:\)</span>noise(sparse)<br />
Robust PCA:<span class="arithmatex">\(minrank(L)+\lambda\|S\|_0,subject\ to\ L+S=X\)</span>(NP-hard)<br />
PCP surrogate error:<span class="arithmatex">\(min\|L\|_*+\lambda \|S\|_1,subject\ to\ L+S=X\)</span>  </p>
<h4 id="autoencoder">AutoEncoder<a class="headerlink" href="#autoencoder" title="Permanent link">&para;</a></h4>
<p>unsupervised NN(x -&gt; z -&gt; x')<br />
embedding:low-dim vector to represent an object<br />
word2vec:<br />
one-hot:(0,0,...,1,0,...,0)<br />
[idea] meaning is given by the words appear close-by<br />
Loglikelihood:<br />
$$ 
\log L(\theta)=\log \frac 1 T \Pi_{t=1}^T\Pi_{-m\le j\le m,j\neq 0}P(w_{t+j}|w_t;\theta)
$$</p>
<h2 id="lecture-26">Lecture 26<a class="headerlink" href="#lecture-26" title="Permanent link">&para;</a></h2>
<h3 id="clustering">Clustering<a class="headerlink" href="#clustering" title="Permanent link">&para;</a></h3>
<p>unsupervised learning task<br />
簇内相似度高，簇间相似度低<br />
external index:compare clustering result with reference model<br />
<span class="arithmatex">\(a=|SS|,b=|SD|,c=|DS|,d=|DD|,S:\)</span>same,<span class="arithmatex">\(D:\)</span>different<br />
<span class="arithmatex">\(a+b+c+d=m(m-1)/2\)</span><br />
Jaccard:<span class="arithmatex">\(JC=\frac{a}{a+b+c}\)</span><br />
FM:<span class="arithmatex">\(FMI=\sqrt{\frac{a}{a+b}\cdot\frac{a}{a+c}}\)</span><br />
validity index/internal index:DB,Dunn just base on cluster result<br />
distance:<span class="arithmatex">\(dist_{mk}(x_i,x_j)=(\sum_{u=1}^n|x_{iu}-x_{ju}|^p)^{\frac 1 p}\)</span>    </p>
<ul>
<li>原型聚类：K-means,LVQ,GMC  </li>
<li>密度聚类：样本分布紧密程度确定聚类结构  </li>
<li>层次聚类：不同层次数据集划分形成树形聚类结构  </li>
</ul>
<h4 id="_1">原型聚类<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h4>
<h5 id="k-means">k-means<a class="headerlink" href="#k-means" title="Permanent link">&para;</a></h5>
<ol>
<li>random select k samples as center<br />
loop:  </li>
<li>compute dist and cluster the data into k clusters  </li>
<li>update mean vector of each cluster and find new cluster centre  </li>
<li>stop until no cluster centre changes  </li>
</ol>
<p>Q1:better random k samples selection:<br />
K-means++:choose the centers with large distance<br />
multiple-times K-means<br />
choose a centre,then choose the farthest,until we get k samples<br />
Q2:how to select k?<br />
draw SSE with multiple k,select the k with the lowest SSE  </p>
<h5 id="learning-vector-quantizationlvq">Learning Vector Quantization,LVQ<a class="headerlink" href="#learning-vector-quantizationlvq" title="Permanent link">&para;</a></h5>
<p>labelled clustering<br />
modify center p:<span class="arithmatex">\(p'=p_{i*}+(y_j==t_{i*}?1:-1)\eta\cdot(x_j-p_{i*})\)</span>  </p>
<h5 id="gaussian-mixture-clusteringgmc">Gaussian Mixture Clustering,GMC<a class="headerlink" href="#gaussian-mixture-clusteringgmc" title="Permanent link">&para;</a></h5>
<p>Assume each cluster is a Gaussian distribution<br />
<span class="arithmatex">\(p_M(x)=\sum_{i=1}^k\alpha_i\cdotp(x|\mu_i,\Sigma_i)\)</span><br />
Then learn the parameters based on maximum likelihood<br />
EM algorithm:<br />
E. compute post-probability <span class="arithmatex">\(\gamma_{ji}=p_M(z_j=i|x_j)\)</span><br />
M. update model parameters <span class="arithmatex">\(\left\{(\alpha_i,\mu_i,\Sigma_i)|1\le i\le k\right\}\)</span>  </p>
<h4 id="_2">密度聚类<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h4>
<h5 id="dbscan">DBSCAN<a class="headerlink" href="#dbscan" title="Permanent link">&para;</a></h5>
<p>核心对象:<span class="arithmatex">\(x_j\)</span>的<span class="arithmatex">\(\epsilon\)</span>-邻域包含样本足够多<br />
密度直达，密度可达，密度相连<br />
<img alt="" src="image-35.png" />  </p>
<h4 id="_3">层次聚类<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h4>
<h5 id="agnesagglomerative-nesting">AGNES(AGglomerative NESting)<a class="headerlink" href="#agnesagglomerative-nesting" title="Permanent link">&para;</a></h5>
<ol>
<li>每个样本一个簇  </li>
<li>合并最近的两个簇  </li>
<li>直到所有样本都属于一个簇<br />
output: tree hierarchy  </li>
</ol>
<h3 id="feature-selection">feature selection<a class="headerlink" href="#feature-selection" title="Permanent link">&para;</a></h3>
<p>search candidate subset -&gt; evaluation -&gt; next candidate<br />
search:前向搜索（逐步添加），后向搜索（逐步删除），双向搜索<br />
evaluation:entropy(similar to ID3)  </p>
<h4 id="_4">过滤式选择<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h4>
<p>Relief(Relevant feature):a relevant statistics for each feature to measure its importance<br />
near-hit:同类样本最近邻<span class="arithmatex">\(x_{i,nh}\)</span><br />
near-miss:异类样本最近邻<span class="arithmatex">\(x_{i,nm}\)</span><br />
relevant statistics:<span class="arithmatex">\(\delta^j=\sum_i-diff(x_i^j,x_{i,nh}^j)^2+diff(x_i^j,x_{i,nm}^j)^2\)</span>,near-hit比near-miss越近，属性<span class="arithmatex">\(j\)</span>越有用   </p>
<h4 id="_5">包裹式选择<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h4>
<p>将学习器性能作为特征子集的评价准则<br />
LVW(Las Vegas Wrapper)：随机子集搜索 -&gt; RL  </p>
<h4 id="_6">嵌入式选择<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h4>
<p>训练过程自动选择特征（LASSO）  </p>
<h3 id="sparse-encoding">sparse encoding<a class="headerlink" href="#sparse-encoding" title="Permanent link">&para;</a></h3>
<p>dictionary learning:find a code mapping from dense representation to sparse representation<br />
dictionary:<span class="arithmatex">\(B\)</span>,sparse representation:<span class="arithmatex">\(\alpha_i\in\mathbb{R}^k\)</span><br />
where <span class="arithmatex">\(k\)</span> is the token number in the dictionary<br />
$$
min_{B,\alpha_i}\sum_{i=1}^m|x_i-B\alpha_i|<em i="1">2^2+\lambda\sum</em>^m|\alpha_i|_1
$$
*VQVAE  </p>
<h4 id="compressive-sensing">compressive sensing<a class="headerlink" href="#compressive-sensing" title="Permanent link">&para;</a></h4>
<p>[Goal] reconstruct original signal from compressive data<br />
<span class="arithmatex">\(y=\Phi x,y\)</span> of length <span class="arithmatex">\(n,x\)</span> of length <span class="arithmatex">\(m,n&lt;&lt;m\)</span><br />
<span class="arithmatex">\(\exists \Psi\in \mathbb{R}^{m\times m},x=\Psi s,y=\Phi\Psi s=As\)</span><br />
restore <span class="arithmatex">\(x\iff min_s\|s\|_0,s.t.y=As\)</span><br />
transformation to L1 norm problem then apply LASSO:<br />
<span class="arithmatex">\(min_s\|s\|_1,s.t.y=As\)</span><br />
矩阵补全:<span class="arithmatex">\(min_Xrank(X),s.t.(X)_{ij}=(A)_{ij},(i,j)\in\Omega\)</span>,where <span class="arithmatex">\(A\)</span> is the original matrix(to be restored),<span class="arithmatex">\(\Omega\)</span> is the index of observed elements  </p>
<h2 id="lecture-27">Lecture 27<a class="headerlink" href="#lecture-27" title="Permanent link">&para;</a></h2>
<h3 id="semi-supervised-learning">Semi-supervised learning<a class="headerlink" href="#semi-supervised-learning" title="Permanent link">&para;</a></h3>
<p>labeled sample <span class="arithmatex">\(D_l\)</span> and unlabeled samples <span class="arithmatex">\(D_u\)</span> both exist <span class="arithmatex">\(l&lt;&lt;u\)</span><br />
聚类假设：数据存在簇结构，同一簇属于同一类别<br />
流形假设：数据分布在流形上，邻近样本输出相似<br />
active learning:first train on labeled samples and get confidence;then find important unlabeled samples and label them manually   <br />
纯半监督学习，直推学习（pseudo label）  </p>
<h4 id="_7">生成式方法<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h4>
<p>假设样本由高斯混合模型生成，每个类别对应一个高斯混合成分 <span class="arithmatex">\(p(x)=\sum_{i=1}^N\alpha_i\cdot p(x|\mu_i,\Sigma_i)\)</span><br />
利用极大似然估计高斯混合模型的参数<br />
solution:EM algorithm  </p>
<h4 id="svm">半监督SVM<a class="headerlink" href="#svm" title="Permanent link">&para;</a></h4>
<p>S<sup>3</sup>VM:tries to separate the labeled samples and cross the low-density data area<br />
TSVM:find the largest margin classfier by regarding each of all the unlabeled samples as positive or negative    </p>
<h4 id="_8">图半监督学习<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h4>
<p>样本对应节点，边表示相似度<br />
能量函数<span class="arithmatex">\(minE(f)=\frac 1 2 \sum_i\sum_j(W)_{ij}(f(x_i)-f(x_j))^2=f^T(D-W)f,D_{ii}=\sum_jW_{ij},f=(f_l^Tf_u^T)^T,D-W:\)</span>拉普拉斯矩阵，图结构的平滑性<br />
<span class="arithmatex">\(\nabla f=0\Rightarrow f_u=(D_{uu}-W_{uu})^{-1}W_{ul}f_l\)</span><br />
样本在<span class="arithmatex">\(W\)</span>上越接近，预测结果<span class="arithmatex">\(f\)</span>要尽可能接近<br />
概率转移矩阵<span class="arithmatex">\(P=D^{-1}W\)</span>  </p>
<h4 id="disagreement">基于分歧disagreement的方法<a class="headerlink" href="#disagreement" title="Permanent link">&para;</a></h4>
<p>属性集，视图<br />
相容性：不同视图输出信息一致<br />
1. 在每个视图上基于有标签的样本分类分类器<br />
2. 在每个视图挑选最有把握的未标记样本标记作为另一个视图的学习样本<br />
3. 互相学习、共同进步  </p>
<h4 id="_9">半监督聚类<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h4>
<p>must-link set M,cannot-link set C to constrain k-means  </p>
<h2 id="lecture-28">Lecture 28<a class="headerlink" href="#lecture-28" title="Permanent link">&para;</a></h2>
<h3 id="_10">概率图模型<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h3>
<h4 id="hmm">隐马尔可夫模型(HMM)<a class="headerlink" href="#hmm" title="Permanent link">&para;</a></h4>
<p>概率模型：描述框架，将学习任务归结为概率计算<br />
关系变量Y,可观测变量O，其他变量R，生成式模型考虑<span class="arithmatex">\(P(Y,R,O)\)</span>,判别式模型考虑<span class="arithmatex">\(P(Y,R|O)\)</span>，推断<span class="arithmatex">\(P(Y|O)\)</span><br />
状态变量/隐变量，观测变量<br />
例：<span class="arithmatex">\(P(Rainy)=0.6,P(Sunny)=0.4,P(Rainy|Rainy)=0.7,P(Sunny|Rainy)=0.3,P(Rainy|Sunny)=0.4,P(Sunny|Sunny)=0.6,P(walk|Rainy)=0.1,P(shop|Rainy)=0.4,P(clean|Rainy)=0.5,P(walk|Sunny)=0.6,P(shop|Sunny)=0.3,P(clean|Sunny)=0.1\)</span><br />
[Problem] Given the activity the person does,predict the weather<br />
概率图模型：变量关系图，节点表示随机变量，边表示概率关系<br />
有向无环图：贝叶斯网，无向图：马尔可夫网<br />
马尔可夫链：现在决定未来（马尔可夫性）<br />
$$
P(x_1,y_1,...,x_n,y_n)=P(y_1)P(x_1|y_1)\Pi_{i=2}^nP(y_i|y_{i-1})P(x_i|y_i)
$$
状态转移概率<span class="arithmatex">\(A=[a_{ij}]_{N\times N},a_{ij}=P(y_{t+1}=s_j|y_t=s_i\)</span><br />
输出现测概率<span class="arithmatex">\(B=[b_{ij}]_{N\times M},b_{ij}=P(x_t=o_j|y_t=s_i)\)</span><br />
初始状态概率<span class="arithmatex">\(\bold{\pi}\)</span><br />
维特比算法:<br />
1. 初始化：<span class="arithmatex">\(\delta_1(i)\)</span><br />
2. 递推：逐步计算每个<span class="arithmatex">\(t\)</span>时刻最大概率<span class="arithmatex">\(\delta_t(j)\)</span>,记录路径<span class="arithmatex">\(\psi_t(j)\)</span><br />
$$
\delta_t(j)=max_{1\le i\le n}[\delta_{t-1}(i)a_{ij}]b_j(x_t)
$$
$$
\psi_t(j)=argmax_{1\le i\le n}[\delta_{t-1}(i)a_{ij}]
$$
3. 终止<br />
$$
y_n=argmax_{1\le i\le n}\delta_n(i)
$$
$$
P^*=max_{1\le i\le n}\delta_n(i)
$$
4. 回溯
$$
y_t=\psi_{t+1}(y_{t+1})
$$</p>
<h4 id="mrf">马尔可夫随机场(MRF)<a class="headerlink" href="#mrf" title="Permanent link">&para;</a></h4>
<p>无向图+势函数/因子（定义概率分布函数）<br />
<span class="arithmatex">\(\psi_{AC}(x_A,x_C)=\begin{cases}1.5,if\ x_B=x_C\\0.1,otherwise\end{cases}\)</span><br />
势函数常用指数定义<span class="arithmatex">\(\psi_Q(x_Q)=e^{-H_Q(x_Q)},H_Q(x_Q)=\sum_{u,v\in Q,u\neq v}\alpha_{uv}x_ux_v+\sum_{v\in Q}\beta_vx_v\)</span><br />
团，极大团定义同fds<br />
多个变量的联合概率分布为所有极大团势函数的乘积的归一化<br />
<span class="arithmatex">\(P(x)=\frac 1 Z\Pi_{Q\in\mathcal{C}}\psi_Q(x_Q)\)</span><br />
分离集：两个结点集A,B，A到B必须经过集合C，则A和B被C分离<br />
全局马尔可夫性：给定两个变量子集的分离集，两个子集条件独立  </p>
<h4 id="crf">条件随机场(CRF)<a class="headerlink" href="#crf" title="Permanent link">&para;</a></h4>
<p>给定观测值后的条件概率建模，e.g.词性标注，语法分析<br />
条件随机场：图G满足马尔可夫性<span class="arithmatex">\(P(y_v|x,y_{V\backslash\left\{v\right\}}=P(y_v|x,y_{n(v)},n(v):\)</span>neighbor of <span class="arithmatex">\(v\)</span><br />
条件概率，转移特征，状态转移类似MRF与HMM的结合  </p>
<h4 id="_11">学习与推断<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h4>
<p>变量消去：<span class="arithmatex">\(P(x_5)=\sum_{x_4}\sum_{x_3}\sum_{x_2}\sum_{x_1}P(x_1,x_2,x_3,x_4,x_5)\stackrel{Markov\ property}{=}\sum_{x_4}\sum_{x_3}\sum_{x_2}\sum_{x_1}P(x_1)P(x_2|x_1)P(x_3|x_2)P(x_4|x_3)P(x_5|x_3)=\sum_{x_3}P(x_5|x_3)\sum_{x_4}P(x_4|x_3)...=...=m_{35}(x_5):\)</span>message from 3 to 5  <br />
无向图：概率由势函数表示  </p>
<h4 id="_12">近似推断<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h4>
<h5 id="mcmc">MCMC采样<a class="headerlink" href="#mcmc" title="Permanent link">&para;</a></h5>
<p>$<span class="arithmatex">\(E_p[f]=\int f(x)p(x)dx\)</span>$
$<span class="arithmatex">\(\hat{f}=\frac 1 N \sum_{i=1}^N f(x_i)\)</span>$
纯蒙特卡洛采样在高维空间可能很难采出有效样本<br />
马尔科夫链蒙特卡洛：通过转移函数变换采样空间<br />
平稳过程（停止采样）：<span class="arithmatex">\(p(x^t)T(x^{t-1}|x^t)=p(x^{t-1})T(x^t|x^{t-1})\)</span>
Metropolis-Hasting,MH：<br />
先验转移概率<span class="arithmatex">\(Q(x^* |x^{t-1})\)</span>,接受采样概率<span class="arithmatex">\(A(x^* |x^{t-1})\)</span></p>
<h5 id="variational-inference">变分推断（variational inference)<a class="headerlink" href="#variational-inference" title="Permanent link">&para;</a></h5>
<p>对<span class="arithmatex">\(p(x|\Theta)=\Pi_{i=1}^N \sum_x p(x_i,x|\Theta)\)</span>做似然估计<br />
<span class="arithmatex">\(ln p(x)=L(q)+KL(q || p)\)</span>  </p>
<h2 id="final-review">Final Review<a class="headerlink" href="#final-review" title="Permanent link">&para;</a></h2>
<p>10 multiple choices(2' * 10) + 7 Q&amp;A(10' * 2 + 12' * 5)<br />
topics:<br />
1. ML basic/evaluation metrics<br />
2. bayesian(见作业2，注意贝叶斯分类器是生成式模型)<br />
3. MLE<br />
4. linear regression/classification<br />
5. NN<br />
6. Decision Tree<br />
7. bagging &amp; boosting<br />
8. KNN(no A-KNN)<br />
9. clustering:k-means<br />
10. dimensional reduction:PCA,LDA<br />
11. RL  </p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright © YYC 2025
    </div>
  
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://tapir-elithril.github.io/Notebook/" target="_blank" rel="noopener" title="tapir-elithril.github.io" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:<3230105697@zju.edu.cn>" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M536.4-26.3c9.8-3.5 20.6-1 28 6.3s9.8 18.2 6.3 28l-178 496.9c-5 13.9-18.1 23.1-32.8 23.1-14.2 0-27-8.6-32.3-21.7l-64.2-158c-4.5-11-2.5-23.6 5.2-32.6l94.5-112.4c5.1-6.1 4.7-15-.9-20.6s-14.6-6-20.6-.9l-112.4 94.3c-9.1 7.6-21.6 9.6-32.6 5.2L38.1 216.8c-13.1-5.3-21.7-18.1-21.7-32.3 0-14.7 9.2-27.8 23.1-32.8z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["navigation.tabs", "navigation.top", "navigation.indexes", "navigation.expand", "search.suggest", "search.highlight", "content.code.copy", "content.action.edit"], "search": "../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../../javascripts/extra.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>